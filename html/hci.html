<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title></title>
  <link rel="stylesheet" href="_pandoc.css" type="text/css" />
  <link href='http://fonts.googleapis.com/css?family=Lato:300,700,300italic' rel='stylesheet' type='text/css'>
</head>
<body>
<div id="TOC">
<ul>
<li><a href="#human-computer-interaction---2012---002">Human-Computer Interaction - 2012 - 002</a><ul>
<li><a href="#lecture-notes">Lecture notes</a><ul>
<li><a href="#human-computer-interaction">1.1: Human Computer Interaction</a></li>
<li><a href="#the-power-of-prototyping">1.2: The Power of Prototyping</a></li>
<li><a href="#evaluating-designs">1.3: Evaluating Designs</a></li>
<li><a href="#the-birth-of-hci.">1.4: The Birth of HCI.</a></li>
<li><a href="#participant-observation">2.1: Participant Observation</a></li>
<li><a href="#interviewing">2.2: Interviewing</a></li>
<li><a href="#additional-needfinding-strategies">2.3: Additional needfinding strategies</a></li>
<li><a href="#paper-prototypes-and-mockups">3.1: Paper Prototypes and Mockups</a></li>
<li><a href="#faking-it---wizard-of-oz-prototyping">3.2: Faking it - Wizard-of-Oz Prototyping</a></li>
<li><a href="#faking-it---video-prototyping">3.3: Faking It - Video Prototyping</a></li>
<li><a href="#creating-and-comparing-alternatives">3.4: Creating and comparing alternatives</a></li>
<li><a href="#heuristic-evaluation-why-and-how.">4.1: Heuristic Evaluation, why and how.</a></li>
<li><a href="#design-heuristics-part-1-of-2">4.2: Design Heuristics (part 1 of 2)</a></li>
<li><a href="#design-heuristics-part-2-of-2">4.3: Design Heuristics (part 2 of 2)</a></li>
<li><a href="#direct-manipulation">5.1: Direct manipulation</a></li>
<li><a href="#mental-models">5.2: Mental Models</a></li>
<li><a href="#representation-matters">5.3 Representation Matters</a></li>
<li><a href="#distributing-cognition-part-1-of-2">5.4: Distributing Cognition (part 1 of 2)</a></li>
<li><a href="#distributing-cognition-part-2-of-2">5.5: Distributing Cognition (part 2 of 2)</a></li>
<li><a href="#visual-design">6.1: Visual Design</a></li>
<li><a href="#typography">6.2: Typography</a></li>
<li><a href="#grids-and-alignment">6.3: Grids and Alignment</a></li>
<li><a href="#reading-and-navigating">6.4: Reading and Navigating</a></li>
<li><a href="#design-studies-you-can-learn-from">7.1: Design Studies You Can Learn From</a></li>
<li><a href="#assign-participants-to-conditions">7.2: Assign Participants to Conditions</a></li>
<li><a href="#in-person-experiments">7.3: In person experiments</a></li>
<li><a href="#a-running-web-experiments-1">7.4a: Running Web Experiments (1)</a></li>
<li><a href="#b-running-web-experiments-2">7.4b: Running web experiments (2)</a></li>
<li><a href="#c-running-web-experiments-3">7.4c: Running web experiments (3)</a></li>
<li><a href="#comparing-rates">6.5: Comparing rates</a><ul>
<li><a href="#readings">Readings:</a></li>
</ul></li>
</ul></li>
<li><a href="#assignment-notes">Assignment notes</a></li>
<li><a href="#general-notes">General notes</a></li>
</ul></li>
</ul>
</div>
<h1 id="human-computer-interaction---2012---002"><a href="#TOC">Human-Computer Interaction - 2012 - 002</a></h1>
<p>(via Coursera)</p>
<h2 id="lecture-notes"><a href="#TOC">Lecture notes</a></h2>
<h3 id="human-computer-interaction"><a href="#TOC">1.1: Human Computer Interaction</a></h3>
<ul>
<li>Often iterative.</li>
<li>Focus on users.</li>
<li>Good design shifts user’s attention from manipulating the interface to accomplishing a task.</li>
<li>People’s tasks, goals, and values drive development.</li>
<li>Work with users, but they’re just one stakeholder.</li>
</ul>
<h3 id="the-power-of-prototyping"><a href="#TOC">1.2: The Power of Prototyping</a></h3>
<ul>
<li>Reflective conversation with materials.</li>
<li>Goal is not artifact, it is feedback.</li>
<li>Question rendered as an artifact for other designers or users. Ask lots of questions.</li>
<li>Prototypes are nearly always, and should be, incomplete.</li>
<li>Prototyping is a strategy for efficiently dealing with things that are hard to predict.</li>
<li>Focus on goals, evolve the designs.</li>
<li>The rights of a prototype:
<ul>
<li>Should not be required to be complete.</li>
<li>Should be easy to change.</li>
<li>Gets to retire.</li>
</ul></li>
<li>Rapid prototyping is simulated annealing; local improvement isn’t enough.</li>
</ul>
<h3 id="evaluating-designs"><a href="#TOC">1.3: Evaluating Designs</a></h3>
<ul>
<li>Different methods achieve different goals.</li>
<li>Iteratively bring people into your office and watch them (usability studies).
<ul>
<li>Setting isn’t valid, but can still learn lessons.</li>
<li>Experimental bias; users try harder, be nicer.</li>
<li>Psychological burden to bring someone to you.</li>
</ul></li>
<li>Surveys
<ul>
<li>Easy to execute and analyse results.</li>
<li>Difference between what people say and what people do.</li>
</ul></li>
<li>Focus Groups
<ul>
<li>Groups of people different. People more submissive or erratic due to group psychology.</li>
<li>Difficult for taboo topics or sexual topics.</li>
</ul></li>
<li>Feedback from Experts
<ul>
<li>Heuristic evaluation.</li>
</ul></li>
<li>Comparative Experiments.
<ul>
<li>Which option is more effective.</li>
<li>Better then surveys because you see what users do.</li>
<li>Better than usability studies because involves more than one option.</li>
<li>But if online can’t see them, and if in person the contrived setting may bias results.</li>
</ul></li>
<li>Participant Observation.
<ul>
<li>What users do in their actual scenario, not just short term.</li>
</ul></li>
<li>Simulation models.</li>
<li>Issues to consider
<ul>
<li>Reliability / precision</li>
<li>Generalisability.</li>
<li>Realism.</li>
<li>Comparison.</li>
<li>Work involved.</li>
</ul></li>
</ul>
<h3 id="the-birth-of-hci."><a href="#TOC">1.4: The Birth of HCI.</a></h3>
<ul>
<li>Vannevar Bush wrote article in 1940 in the Atlantic about Memex.
<ul>
<li>Envisioned how future coulod allow people to produce and consume infomation.</li>
<li>Camera on head, hypertext.</li>
</ul></li>
<li>Grace Hopper invented the compiler and their interfaces.</li>
<li>Graphical User Interface.
<ul>
<li>Input over output, so more intuitive.</li>
</ul></li>
<li>Doug Engelbart invented the mouse.</li>
<li>Alan Kay, at Xerox PARC, prototyped the Dynabook, created the WIMP Windows-Icon-Mouse-Pointer (WIMP) GUI.</li>
</ul>
<h3 id="participant-observation"><a href="#TOC">2.1: Participant Observation</a></h3>
<ul>
<li>“You can observe a lot just by watching”.</li>
<li>Tacit knowledge: deep hanging out.</li>
<li>Five questions:
<ul>
<li>What do people do now?</li>
<li>What values and goals do people have?</li>
<li>How are these activities embedded in larger ecology?
<ul>
<li>e.g. buses. What leads people to need buses?</li>
<li>Broaden your scope.</li>
</ul></li>
<li>Similarities and differences across people.</li>
<li>…and other types of context, like time of day.</li>
</ul></li>
<li>Apprentice yourself.
<ul>
<li>Set up partnership with observee.</li>
<li>Be taught the process.</li>
<li>Observer practices.</li>
<li>Validate your observations; ask observee what they mean.</li>
</ul></li>
<li>Pay attention to all artifacts.
<ul>
<li><strong>Look for workarounds and hacks.</strong></li>
<li><strong>Errors are a goldmine</strong>.</li>
</ul></li>
<li><strong>Difference between what people say and what people do.</strong></li>
</ul>
<h3 id="interviewing"><a href="#TOC">2.2: Interviewing</a></h3>
<ul>
<li>Choosing participants.
<ul>
<li>May be current users, or also non-users but potential future users.</li>
<li>Use incentives and motivation; in SF $50-100, or gift certificate.</li>
<li>Approximate if necessary; better than nothing.</li>
</ul></li>
<li>Malcolm Gladwell
<ul>
<li>Everything is interesting. Be curious.</li>
<li>Don’t start at the top or bottom. Start at the middle. Talk to the people who actually do the work.</li>
<li>People at the top have power to lose, not as interested in sharing knowledge.</li>
</ul></li>
<li>Bad questions.
<ul>
<li>No: “Is the daily update an important feature to you?”</li>
<li>Don’t lead people. Use data to back up open ended questions.</li>
<li>Yes: “Judging by logs I see that you don’t use the daily update feature? Tell me more. Why is that?”</li>
<li>No: “What would you like in a tool?”.</li>
<li>Users don’t know about design, can’t help you like this.</li>
<li>Other types of question to avoid:
<ul>
<li>Likes and wants in hypothetical scenarios.</li>
<li>How often they do things.</li>
<li>How much they like things on an absolute scale.</li>
<li>Avoid binary questions.</li>
</ul></li>
</ul></li>
<li>Good questions
<ul>
<li>Open ended, especially at beginning.</li>
<li>(A little bit of) silence is golden. Let them answer.</li>
</ul></li>
</ul>
<h3 id="additional-needfinding-strategies"><a href="#TOC">2.3: Additional needfinding strategies</a></h3>
<ul>
<li>Longitudinal or sporadic behavior?
<ul>
<li><strong>Diary studies.</strong>
<ul>
<li>Give them a diary, complete at a specified time or interval.</li>
<li>Structured task.</li>
<li>Written, camera, voice; but tailor to context.</li>
<li>Scales better than direct observation.</li>
<li>Entries must be as frictionless as possible. Better results.</li>
<li>May require practice, training, reminding.</li>
</ul></li>
</ul></li>
<li><strong>Experience Sampling, aka pager studies</strong>
<ul>
<li>Phone beeps, then you fill in a form.</li>
<li>Psychometric.</li>
</ul></li>
<li><strong>Lead users</strong>
<ul>
<li>Individually create solutions to their problems.</li>
<li>Designers collaborate to bring their solutions to market.</li>
<li>Before early adopters.</li>
<li>Don’t work well if the improvement is process or knowledge based; difficult to diffuse / market.</li>
</ul></li>
<li><strong>Extreme users.</strong>
<ul>
<li>Everyone gets email. But some people get a lot.</li>
<li>Sometimes some useful ideas, but they’re not representitive users.</li>
</ul></li>
<li>Keeping users in mind.
<ul>
<li>Don’t forget users!</li>
<li><strong>Personas</strong>.
<ul>
<li>A model of a person, an example.</li>
<li>Demographics, motivation, beliefs, intentions, behaviour, and goals.</li>
<li>Draw a picture or have a photo of persona.</li>
<li>Name, occupation, background, social situation, hopes, dreams, and goals. A story!</li>
<li>You can build empathy. Empathy leads to insights.</li>
<li>Keep design consistent over time.</li>
</ul></li>
</ul></li>
<li>Ultimately, it’s about design. This will help you find one, but not strict.</li>
</ul>
<h3 id="paper-prototypes-and-mockups"><a href="#TOC">3.1: Paper Prototypes and Mockups</a></h3>
<ul>
<li>Over course of project fidelity increases.
<ul>
<li>Storyboard, lowest.</li>
<li>Paper prototypes, low.</li>
<li>Digital mockups, low.</li>
<li>Onwards.</li>
</ul></li>
<li><strong>Don’t focus on user interface before focusing on the task at hand</strong>.</li>
<li><strong>Storyboarding isn’t about pretty pictures, it’s about communicating ideas</strong>.</li>
<li>Star people
<ul>
<li>Circle, then body like a star. Very crude. Then add sight lines, boards.</li>
</ul></li>
<li>First objective: <strong>illustrate a goal</strong>.</li>
<li>Last objective: <strong>people accomplishing goals</strong>.</li>
<li>Storyboards should convey:
<ul>
<li><strong>Settings</strong>.
<ul>
<li>People, environment, tasks.</li>
</ul></li>
<li><strong>Sequence</strong>
<ul>
<li>Steps.</li>
<li>What leads someone to use the app, impetus?</li>
<li>What task is being illustrated?</li>
</ul></li>
<li><strong>Satisfaction</strong>
<ul>
<li>What motivates people to use system?</li>
<li>What does it enable people to accomplish?</li>
<li>What need does the system fill?</li>
</ul></li>
</ul></li>
<li>Benefits of storyboarding
<ul>
<li><strong>Holistic</strong>. Emphasize how interfaces accomplish tasks without commiting to particular interfaces.</li>
<li>Gets all the stakeholders on the same page with respect to the goal.</li>
</ul></li>
<li>Time limits help, e.g. 10 minutes per panel.</li>
<li>Then, <strong>paper prototyping</strong>.</li>
<li>Paper prototyping tips and tricks
<ul>
<li>Get a physical box and put all materials in one place! easy to lose or damage it.</li>
<li>Work quickly, reuse by e.g. photocopying.</li>
<li>If something is difficult to simulate allow users to ask verbal questions.</li>
<li>Mix and match hardware and software. Print out a photo of the hardware then put software elements in it.</li>
</ul></li>
<li><strong>Test multiple paper prototypes simultaneously</strong>.</li>
<li>Get users or other stakeholders to help design.</li>
<li>Form and feedback co-evolve. Fidelity increases, feedback detail increases.</li>
<li>Further reading:
<ul>
<li>Bill Buxton, Sketching User Experiences.</li>
<li>Bill Moggridge, designing Interactions.</li>
<li>Carolyn Snyder, Paper Prototyping.</li>
<li>Michael Schrage, Serious Play</li>
<li>Houde and Hill, What do Prototypes Prototype?</li>
<li>Todd Zaki Warfel, Prototyping</li>
</ul></li>
</ul>
<h3 id="faking-it---wizard-of-oz-prototyping"><a href="#TOC">3.2: Faking it - Wizard-of-Oz Prototyping</a></h3>
<ul>
<li>Simulate machine behaviour with human operators.</li>
<li>Make an interactive application without much code.</li>
<li>Get feedback from users.
<ul>
<li>Hi fidelity =&gt; users think it’s real, more reluctant to be critical.</li>
<li>Low fidelity =&gt; more license to suggest changes.</li>
</ul></li>
<li>Steps:
<ol style="list-style-type: decimal">
<li>Map out scenarios and application flow.
<ul>
<li>What happens in response to user behavour?</li>
</ul></li>
<li>Put together interface skeletons.</li>
<li>Develop “hooks” for wizard input.</li>
<li>Where and how the wizard will provide input.
<ul>
<li>Remember you’ll eventually replace with software.</li>
</ul></li>
<li>Rehearse wizard role with a colleague.</li>
</ol></li>
<li>Running wizard-powered prototypes:
<ul>
<li>Practice with a friend first.</li>
<li>Once comfortable recruit “users”: train stations, cafes, etc.</li>
<li>Two roles: facilitator and wizard.
<ul>
<li>Facilitator: provides tasks and takes notes.</li>
<li>Wizard: operator interface (more authenticate if hidden or remote).</li>
</ul></li>
<li>User feedback could be:
<ul>
<li>Think aloud.</li>
<li>Retrospective (if thinking aloud is distracting).</li>
<li>Heuristic evaluation</li>
<li>Debrief and reward users.</li>
</ul></li>
</ul></li>
<li>Advantages:
<ul>
<li>Faster, cheaper, quicker iterations.</li>
<li>Creating multiple variations easy.</li>
<li>More “real” than paper prototypes.</li>
<li>Identifies bugs and problems with current design.</li>
<li>User-centric.</li>
<li>Can evision very difficult ideas now.</li>
<li>Designers learn too.</li>
</ul></li>
<li>Disadvantages:
<ul>
<li>May be too optimistic about technology, e.g. perfect speech recognition.</li>
<li>Technology may never be possible.</li>
<li>Some features or limitations are too difficult to wizard.</li>
</ul></li>
<li>Further reading:
<ul>
<li>http://speckyboy.com/2012/06/24/10-effective-video-examples-of-paper-prototyping</li>
<li>www.elsevierdirect.com/companion.jsp?ISBN=9780123740373</li>
<li>Stephen Dow</li>
</ul></li>
</ul>
<h3 id="faking-it---video-prototyping"><a href="#TOC">3.3: Faking It - Video Prototyping</a></h3>
<ul>
<li>Benefits:
<ol style="list-style-type: decimal">
<li>Cheap and fast.</li>
<li>Great communication tools.
<ul>
<li>Shows context, self-explanatory.</li>
</ul></li>
<li>Development spec.</li>
<li>Ties interface designs to tasks.
<ul>
<li>Check completeness of interface.</li>
<li>Check nothing extra there.</li>
</ul></li>
</ol></li>
<li>Any fidelity, but usually low.
<ul>
<li>Often coupled with paper prototypes.</li>
</ul></li>
<li>Content
<ul>
<li>Like storyboard, the whole task, including motivation (impetus) and success (narrative).</li>
<li>Draw on tasks you’ve observed.</li>
<li>Illustrate important tasks, MVP.</li>
</ul></li>
<li>Steps:
<ol style="list-style-type: decimal">
<li>Start with outline, or your storyboards.</li>
<li>Camera, people, realistic location.</li>
<li>Focus on message rather than production value.</li>
</ol></li>
<li>Considerations:
<ul>
<li>Audio or silent? Audio can be finicky, can use cue cards instead.</li>
<li>Interface can be paper, mock-ups, code, or invisible (just showing task)</li>
<li>Can show both success and failure.</li>
<li>Edit as little as possible, editing sucks.</li>
</ul></li>
<li>Furher reading:
<ul>
<li>Wendy MacKay.</li>
</ul></li>
</ul>
<h3 id="creating-and-comparing-alternatives"><a href="#TOC">3.4: Creating and comparing alternatives</a></h3>
<ul>
<li>Duncker: <strong>functional fixation</strong>
<ul>
<li>Once objects are biased to a particular purpose it’s difficult to see them otherwise.</li>
</ul></li>
<li><strong>Prototype in parallel</strong>, not in serial.
<ul>
<li>More diverse output, simulated annealing escapes local maxima.</li>
<li>Better rated output.</li>
</ul></li>
<li>Separating ego from artifact.
<ul>
<li>If you have different ideas, it’s easier to see that judgements are based on your artifacts.</li>
</ul></li>
<li>Parallel encourages comparison, and comparison aids learning.</li>
<li><strong>Create and share multiple designs</strong>.
<ul>
<li>Feel better in team environments.</li>
<li>Alternatives provides a vocabulary for teams to discuss the space of possible solutions.</li>
</ul></li>
</ul>
<h3 id="heuristic-evaluation-why-and-how."><a href="#TOC">4.1: Heuristic Evaluation, why and how.</a></h3>
<ul>
<li>Empirical: assess with users.</li>
<li>Formal: models and formulas =&gt; measured.</li>
<li>Automated: software measures.</li>
<li>Critique: Expertise and heuristic feedback.
<ul>
<li>When to get critique?</li>
<li><strong>Before user testing</strong>. Allows user testing to focus on big issues.</li>
<li><strong>Before redesigning</strong>. What to keep, what to throw away.</li>
<li><strong>Problems known, but need evidence</strong>. You get complaints, need to articulate.</li>
<li><strong>Before release</strong>: Smooth out rough edges.</li>
</ul></li>
<li><strong>Begin with clear goal</strong>.</li>
<li><strong>Heuristic Evaluation</strong>.
<ul>
<li>Jakob Nielsen, ten heuristics.</li>
<li>3-5 independent evaluators, on working UI or sketches.</li>
<li>Universal principles.</li>
<li>Process.
<ul>
<li>Give them some tasks. Execute each task several times, stepping through the design.</li>
<li>Constantly refer to Nielsen’s heuristics and category-specific heuristics.</li>
<li>Use violations to redesign and fix.</li>
</ul></li>
</ul></li>
<li>Why multiple evaluators?
<ul>
<li>Some evaluators find more problems than others.</li>
<li>No evaluator finds all problems.</li>
<li>But: decreasing returns, cost of evaluation.</li>
</ul></li>
<li>Heuristics vs. user testing.
<ul>
<li>HE is faster.</li>
<li>HE results are pre-interpreted.</li>
<li>UT is more accurate (by definition).</li>
<li>HE can save participants for further testing.</li>
</ul></li>
<li>Heuristic evaluation phases
<ul>
<li><strong>Pre-evaluation training</strong>. Domain knowledge, information on scenarios.</li>
<li><strong>Evaluation</strong>. Independent, then aggregate. Use <strong>severity ratings</strong>.</li>
<li><strong>Debriefing</strong>. Review with design team.</li>
<li>At least two passes for each evalutor. One to get the flow, second for focus.</li>
<li>Produce list of specific problems from a list.
<ul>
<li>Issue, severity rating, heuristics violated, description.</li>
</ul></li>
</ul></li>
<li>Severity rating
<ul>
<li>Frequency, impact, persistence.</li>
<li>Allocate resources to problems.</li>
</ul></li>
</ul>
<h3 id="design-heuristics-part-1-of-2"><a href="#TOC">4.2: Design Heuristics (part 1 of 2)</a></h3>
<ul>
<li><strong>Show system status</strong>.
<ul>
<li>wrt. response time.
<ul>
<li><blockquote>
<p>1s =&gt; spinner.</p>
</blockquote></li>
<li><blockquote>
<blockquote>
<p>1s =&gt; fractional progress indication.</p>
</blockquote>
</blockquote></li>
</ul></li>
<li>wrt space, e.g. disk space.</li>
<li>wrt change, e.g. unsaved changes.</li>
<li>wrt action, e.g. traffic lights.
<ul>
<li>Traffic lights are redundant; red and on top, green and on bottom. Colour blindness.</li>
</ul></li>
<li>wrt next steps. What happened, and what will happen next?</li>
<li>wrt completion. e.g. dialog saying done!</li>
</ul></li>
<li><strong>Familiar metaphors and language</strong>
<ul>
<li>Identify terms and language familiar to users.</li>
<li>Familiar categories.</li>
<li>For esoteric errors explain what actions are available and their consequences.</li>
</ul></li>
<li><strong>User control and freedom</strong>
<ul>
<li>Undo/redo.</li>
<li>Not forcing people down certain paths. Freedom to explore.</li>
<li>Preview paths; it helps them explore. e.g. flight ticket search with calendar of cheapest prices on days.</li>
<li>But context-dependent. e.g. a wizard is easier if very contrained, but bad for experts.</li>
</ul></li>
<li><strong>Consistency and standards</strong>
<ul>
<li>Placement of controls.</li>
<li>Consistent names. User-centric consistency.</li>
<li>Clear choices. Use actions and verbs, not Yes and No.</li>
</ul></li>
<li><strong>Error prevention</strong>
<ul>
<li>Prevent data loss. Warn.</li>
<li>Prevent clutter. Too much means can’t see options.</li>
<li>Prevent confusing flow and use safe defaults.</li>
<li>Prevent bad input.</li>
<li>Prevent unnecessary constaints. e.g. free-text shouldn’t be constained by category. Offer the option but don’t contrain.</li>
</ul></li>
</ul>
<h3 id="design-heuristics-part-2-of-2"><a href="#TOC">4.3: Design Heuristics (part 2 of 2)</a></h3>
<ul>
<li><strong>Recognition over recall</strong>
<ul>
<li>Avoid codes. Else you’ll see post-it notes for people trying to help remember them.</li>
<li>Lead with reasonable defaults to avoid awkward intermediary steps.</li>
<li>Previews allow recognition and more efficient.</li>
</ul></li>
<li><strong>Flexibility and efficiency</strong>
<ul>
<li>Shortcuts for experts.</li>
<li>Use defaults but also simultaneously show options for flexibility. e.g. popular cities in a combo box, text field for other.</li>
<li>Ambient information using icons / sparklines in a dashboard.</li>
<li>Proactivity. Offer options based on behaviour rather than waiting for user.
<ul>
<li>Task relevant, don’t interrupt flow.</li>
</ul></li>
<li>Recommendations.
<ul>
<li>Keep it relevant.</li>
</ul></li>
<li>Don’t go overboard, options have a cost.</li>
</ul></li>
<li><strong>Aethetics and minimalist design</strong>
<ul>
<li>Above the fold. Push common and mainline information up.</li>
<li>Signal to noise.
<ul>
<li>Judicious use of colour.</li>
<li>Keep chrome down.</li>
<li>Collapse login and register page into one page.</li>
</ul></li>
<li>Avoid redundancy.</li>
<li>Avoid unused features.</li>
</ul></li>
<li><strong>Recognize, Diagnose, and Recover from Errors</strong>
<ul>
<li>Make problem clear. Where is the error?</li>
<li>Provide a solution.</li>
<li>Show a path forward.</li>
<li>Propose an alternative. If nothing is found or hit an error, suggest alternatives. “Smart rexlaxation”.</li>
</ul></li>
<li><strong>Help</strong>
<ul>
<li>Examples.</li>
<li>Explain choices using examples, e.g. content of a prospective newsletter.</li>
<li>Explain the options of escaping an error.</li>
<li>Help show the steps. If a sequence of steps required give clues about where to find them.</li>
<li>Help point things out. Highlight elements of UI.</li>
<li>Provide more information.</li>
<li>Be honest and clear, e.g. human-friendly EULAs.</li>
<li>Humour, let users have fun.</li>
</ul></li>
</ul>
<h3 id="direct-manipulation"><a href="#TOC">5.1: Direct manipulation</a></h3>
<ul>
<li>How to improve a measuring cup?
<ul>
<li>Even after user survey of people not complaining about how long it takes to make a measurement, participant observation =&gt; inefficient to make readings.</li>
<li>Be able to make measurements just be looking straight down.</li>
</ul></li>
<li>Simply asking people what they want will miss important opportunities.</li>
<li>Go out into the field, especially with prototypes.</li>
<li><strong>The Gulf of Execution</strong>
<ul>
<li>How does the user know what to do? (“Do?”)</li>
</ul></li>
<li><strong>The Gulf of Evaluation</strong>
<ul>
<li>How does the user know what happened? (“Now?”)</li>
</ul></li>
<li>Six questions.
<ul>
<li>Determine the function of the device?</li>
<li>Tell what actions are possible?</li>
<li>Determine mapping from intention to physical movement?</li>
<li>Perform the action?</li>
<li>Tell what state the system is in? Desired state?</li>
<li>Determine mapping from system state to interpretation.</li>
</ul></li>
<li>To reduce gulfs.
<ul>
<li><strong>Visibility</strong> (affordances, signifiers)</li>
<li><strong>Feedback</strong></li>
<li><strong>Consistency</strong> (standards)</li>
<li><strong>Non-destructive operations</strong> (undo)</li>
<li><strong>Discoverability</strong> (systematic exploration possible)</li>
<li><strong>Reliability</strong> (consistent behaviour, it works).</li>
</ul></li>
<li>Command line vs. GUI
<ul>
<li>GUI offers continuous feedback.</li>
<li>GUI options are all visisible. Discoverable.</li>
</ul></li>
<li>GUI offers <strong>direct manipulation</strong>
<ul>
<li><strong>Immediate feedback on actions</strong></li>
<li><strong>Continuous representations of objects</strong></li>
<li>Leverage metaphor.</li>
</ul></li>
<li>But when is the command line better?
<ul>
<li><strong>Successful indirection</strong>.</li>
<li>Express and combine abstract actions.</li>
</ul></li>
<li>Don Norman, The Design of Everyday Things</li>
</ul>
<h3 id="mental-models"><a href="#TOC">5.2: Mental Models</a></h3>
<ul>
<li>What makes an interface learnable?</li>
<li>What leads to errors?</li>
<li>Goal: <strong>design beacons the right model</strong>.
<ul>
<li>User’s model develops through interaction with system.</li>
<li>Designer’s expect user’s model to match designer’s…but often no!</li>
<li>Mismatched models lead to slow performance, errors, frustration.</li>
</ul></li>
<li><strong>Mental models &lt;= experience, metaphor, analogical reasoning.</strong>
<ul>
<li>“A text processor is like a typewriter”. Encourages users to transer skills and beliefs over.</li>
<li>User models incomplete, vary over time, superstitious.</li>
</ul></li>
<li><strong>Slip</strong>: right model, accidentally do wrong thing.
<ul>
<li>Prevent/fix via ergonomics, visual design.</li>
</ul></li>
<li><strong>Mistake</strong>: do what you want to do but wrong model.
<ul>
<li>Prevent/fix via feedback, improve user’s perception of affordances (visibility).</li>
</ul></li>
<li>Butterfly ballot in 2000 example of mistake.</li>
<li><strong>Consistency and re-use reduce mistakes.</strong></li>
<li><strong>Leverage real-world metaphors</strong>.
<ul>
<li>Direct manipulation provides this.</li>
</ul></li>
<li>New technology necessarily different from what users used to; minimize the gap.</li>
<li>To learn more:
<ul>
<li>JM Carroll, HR Olson, <em>Mental models in human-computer interaction: Research issues</em>, 1987</li>
<li>Don Norman, <em>Design of Everyday Things</em></li>
<li>James Reason, <em>Human Error</em>.</li>
</ul></li>
</ul>
<h3 id="representation-matters"><a href="#TOC">5.3 Representation Matters</a></h3>
<ul>
<li>The Oranges Puzzle, The Bagels Puzzle
<ul>
<li>Like Towers of Hanoi, but food.</li>
</ul></li>
<li>Bagels =&gt; <strong>representation of problem enforces constraints</strong>, easier to handle, less stress for working memory.</li>
<li>The Number Game.
<ul>
<li>Two players, take numbers [1, 9] without replacement, first to sum to 15 wins.</li>
<li>Just in your head is difficult!</li>
<li>With cards a bit easier.</li>
</ul></li>
<li>Tic Tac Toe and Number Game isomorphs!
<ul>
<li>Magic square, sums to 15.</li>
</ul></li>
<li>“Solving a problem simply means representing it so as to make the solution transparent”. - Herbert Simon.</li>
<li><strong>Working memory</strong>.
<ul>
<li>Recall heuristic recognition not recall.</li>
<li><strong>Embed constraints in user interface</strong>.</li>
</ul></li>
<li>e.g. Getting Things Done
<ul>
<li>One rule is when you realise you need to do something write it down. Relieves pressure on working memory.</li>
</ul></li>
<li><strong>Naturalness Principle</strong>: properties of representation match properties of the thing being represented.</li>
<li><strong>World in miniature</strong>. Fit into small diagram to illustrate summary and context of errors.</li>
</ul>
<h3 id="distributing-cognition-part-1-of-2"><a href="#TOC">5.4: Distributing Cognition (part 1 of 2)</a></h3>
<ul>
<li>Think more fluidly by <strong>distributing cognition</strong> into artifacts of the world.
<ul>
<li>Encourage experimentation. (Tetris)</li>
<li>Scaffold learning, reduce errors through redundancy. (Montessouri blocks)</li>
<li>Show only differences that matter. (London Underground)</li>
<li>Convert slow calculation into fast perception. (Map colouring)</li>
<li>Chunking. (Chess and gestures)</li>
<li>Efficiency. (diagrams, GUI)</li>
<li>Collaboration. (cockpits)</li>
</ul></li>
<li><strong>Cheap experimentation</strong>
<ul>
<li>e.g. Tetris. Experts more likely to move pieces around in attempt to determine fit. Offload cognition onto the interface.</li>
</ul></li>
<li><strong>Scaffold learning</strong>
<ul>
<li>Redundantly represent abstract concepts. Reduce errors.</li>
</ul></li>
<li>A good representation:
<ul>
<li><strong>shows all relevant information, and nothing else.</strong></li>
<li>enable comparison, exploration, problem solving.</li>
<li>e.g. London Underground map.
<ul>
<li><strong>focus plus context representation</strong> - Where detail matters, e.g. centre, higher fidelity.</li>
<li>where detail doesn’t matter, e.g. suburbs, less fidelity.</li>
<li>make some tasks easier (get from A to B), necessarily makes others more difficult (measure distance).</li>
</ul></li>
</ul></li>
<li><strong>Nearly all representational design is about fitness to task.</strong><br /></li>
<li>Weather Underground.
<ul>
<li>Better if temperature scannable; colour or scale nodes.</li>
</ul></li>
<li>Edward Tufte, height above sea level map.
<ul>
<li>Hue not comparable (ROY G BIV), more qualitative.</li>
<li><strong>Colour as a meaningful representional cue</strong>.</li>
<li>Earth tones above sea level, blue tones below sea level.</li>
<li>Luminance is comparable.</li>
</ul></li>
<li><strong>Chunking</strong>.
<ul>
<li>Also expertise to build if interface is chunkable, fits in memory.</li>
</ul></li>
</ul>
<h3 id="distributing-cognition-part-2-of-2"><a href="#TOC">5.5: Distributing Cognition (part 2 of 2)</a></h3>
<ul>
<li><strong>Informational Equivalence != Computational Equivalence</strong>
<ul>
<li>Same content, but different representation, =&gt; different efficiency.</li>
<li>e.g. diagrams of geometrical proofs.</li>
</ul></li>
<li>GUI vs. command line.
<ul>
<li>Many tasks can become perception tasks requiring little inference.</li>
</ul></li>
<li>Cockpit instruments have bugs, little physical markers.
<ul>
<li>Allows pilots in cockpit to offload task of coordinating memory about key measurements.</li>
</ul></li>
<li>Examples.</li>
<li>Form validation, do it in real time and show constraints and errors and actions.</li>
<li>Dialog boxes should be action oriented and guide users to likely next step. Provide them with necessary information.</li>
<li>Further reading:
<ul>
<li>Don Norman, Things that Make Us Smart</li>
<li>Edwin Hutchins, Cognition in the Wild</li>
<li>Herbert Simon, Sciences of the Artificial</li>
</ul></li>
</ul>
<h3 id="visual-design"><a href="#TOC">6.1: Visual Design</a></h3>
<ul>
<li><strong>Whitespace conveys grouping.</strong>
<ul>
<li>“Some space must be narrow so that others may be wide. Some space must be empty so that other space may be filled.”</li>
</ul></li>
<li><strong>Use size contrasts to indicate hierarchy</strong>.
<ul>
<li>“Information consists of differences that make a difference.”</li>
</ul></li>
<li><strong>Vary scale and weight</strong>.</li>
<li>Three goals for visual design
<ul>
<li><em>Guide</em>. Convey structure, relative importance, relationships.</li>
<li><em>Pace</em>: Draw people in, orient, provide hooks to dive deep.</li>
<li><em>Message</em>: express meaning and style, breath life into content.</li>
</ul></li>
<li>Blur each page; is hierarchy still clear?</li>
<li>Three basic tools of visual design:
<ul>
<li><em>Typography</em>.</li>
<li><em>Layout</em>.</li>
<li><em>Color</em>.</li>
</ul></li>
<li>A minute to learn, a lifetime to master.</li>
<li>Readings:
<ul>
<li>Jennefier Tidwell’s Designing Interfaces</li>
</ul></li>
</ul>
<h3 id="typography"><a href="#TOC">6.2: Typography</a></h3>
<ul>
<li>Gill Sans, upper-case R.
<ul>
<li>Perceptual uniformity, as opposed to actual uniformity. It looks uniform, but isn’t.</li>
</ul></li>
<li>Elements
<ul>
<li><em>Point size</em>.
<ul>
<li>Implies maximum height, some fonts are less.</li>
</ul></li>
<li><em>Leading</em>.
<ul>
<li>Line spacing.</li>
<li>Pronounced like periodic element; used to use lead to lay out lines.</li>
<li>Default 20% of point size.</li>
</ul></li>
<li><em>x-height</em>
<ul>
<li>Higher =&gt; easier to read at lower point sizes and lower resolutions.
<ul>
<li>e.g. Lucida Bright.</li>
</ul></li>
<li>Lower =&gt; elegance
<ul>
<li>e.g. Baskerville.</li>
</ul></li>
</ul></li>
<li><em>ascenders</em> and <em>descenders</em>
<ul>
<li>How far above x-height do letters extend.</li>
<li>Typically low x-height =&gt; bigger ascenders and descenders.</li>
</ul></li>
<li><em>weight</em>
<ul>
<li>e.g. light, regular, bold.</li>
</ul></li>
<li><em>serifs</em>
<ul>
<li>Flourishes on ends of letters.</li>
</ul></li>
<li><em>small caps</em>
<ul>
<li>Sometimes useful for e.g. fitting in numbers with letters.</li>
<li>By definition no ascenders and descenders.</li>
</ul></li>
</ul></li>
<li>“Which typeface should I use?”
<ul>
<li>Hypothesis: serif more legible for body, sans-serif for headers.</li>
<li>No robust evidence for serif hypothesis.</li>
<li>“Legibility is simply what you’re used to” - Gill.</li>
<li>Top-half of letters contain more information than bottom half.</li>
<li>Expection plays an important role.</li>
<li>For book, common font with large x-height.</li>
<li>For logo, funkier font.</li>
</ul></li>
<li>Experiment with different font faces for same text.</li>
<li>Look around you.</li>
<li>Readings:
<ul>
<li>Robert Bringhurt, The Elements of Typographic Style</li>
<li>Jennifer Tidwell, Designing Interfaces</li>
<li>Edward Tufte, Envisioning Information</li>
<li>Robin Williams, The Non-Designer’s Design Book</li>
<li>Gary Hustwit, Helvetica</li>
</ul></li>
</ul>
<h3 id="grids-and-alignment"><a href="#TOC">6.3: Grids and Alignment</a></h3>
<ul>
<li>Bauhaus Revolution
<ul>
<li>Revolution in use of sans-serif typefaces and grids in the 1920’s.</li>
</ul></li>
<li><strong>Grid</strong>: set of invisible lines that elements snap to.
<ul>
<li>Set of columns.</li>
<li>Set of <strong>gutters</strong>: spacing between columns.</li>
<li>Horizontally aligned using <strong>baselines</strong>.</li>
<li>Add text hierarchically.</li>
<li>Different elements can punch across columns, more dynamic.</li>
<li>Focus plus context; make newer items at top bigger.</li>
<li>Set of columns could be staggered.</li>
<li>When creating templates, design for the longest text block.</li>
</ul></li>
<li><strong>Alignment</strong>
<ul>
<li>In general, left-aligned text is faster to skim for languages read left-to-right.</li>
<li><em>Avoid slight misalignments</em>: undermine ability to beacon organization.</li>
<li><em>Deviate from patterns strategically</em> to draw attention.</li>
<li><em>Use visual proximity and scale</em> to convey semantic information.</li>
</ul></li>
<li><em>Right-alignment</em>
<ul>
<li>For forms can right-align labels then left-align controls. Easier to determine what to fill out.</li>
</ul></li>
<li><em>Heading / subheading</em>
<ul>
<li>Put subheading smaller and more gray scale to draw attention to heading.</li>
</ul></li>
<li><strong>Color</strong>
<ul>
<li>Pay attention to it.</li>
<li>Design in grayscale first.</li>
<li>Keep luminance values from grayscale when moving to color. i.e. black -&gt; gray -&gt; white scale.</li>
<li>All things equal, less colour is more effective.</li>
</ul></li>
<li>Make space, guide the eye.</li>
<li>Readings:
<ul>
<li>Kevin Mullet and Darrel Sano, Designing Visual Interfaces.</li>
<li>Luke Wroblewski, Web Form Design.</li>
<li>Jan Tschichold, The New Typography.</li>
</ul></li>
</ul>
<h3 id="reading-and-navigating"><a href="#TOC">6.4: Reading and Navigating</a></h3>
<ul>
<li>Informavores! People forage and devour information.</li>
<li>Information scent
<ul>
<li>Can people figure out how to get the information they want?</li>
<li>Do they realize what options are available?</li>
</ul></li>
<li>How do you detect poor scent?
<ul>
<li>Flailing.</li>
<li>Low confidence.
<ul>
<li>Right track before and after clicking links.</li>
<li>Before =&gt; high scent.</li>
<li>After =&gt; information beacons intent.</li>
</ul></li>
<li>Back button.</li>
</ul></li>
<li>Low scent pages exhibit e.g.:
<ul>
<li>Surprising information architecture.</li>
<li>Short links (“Transact”?)</li>
<li>Hidden navigation, require mouseover to discover.</li>
<li>Icons add little additional information.</li>
</ul></li>
<li>When do icons help?
<ul>
<li>Facilitate repeat recognition. Reminds you, aids recall.</li>
<li>When you know what it looks like, but not what it’s called. e.g. file extention =&gt; application.</li>
<li>Redundant coding; recall based on either text or icon. Associative learning (icon =&gt; text, text =&gt; icon).</li>
</ul></li>
<li>Improving scent:
<ul>
<li>Lengthen links, multi-word.</li>
<li>Specific, recognizable terms. Not clever terms.</li>
<li>Also improves accessibility.</li>
</ul></li>
<li><strong>Speaking block navigation</strong>
<ul>
<li>Add multiple different words, perhaps in subheadings, to navigation.</li>
</ul></li>
<li>Location of information matters.
<ul>
<li>The Poynter Institute, Eye Track study.</li>
<li>Top-left is priority 1.</li>
<li>Secondary ring around top-left, priority 2.</li>
<li>Further is priority 3.</li>
</ul></li>
<li>People happy to scroll if there is a scent that implies a reward.
<ul>
<li>Put great content in the top fold.</li>
<li>Put indications that content continues if you scroll.</li>
</ul></li>
<li>People don’t read. Nielsen, 1997.</li>
<li>Interlaced browsing. Multiple tasks at once.</li>
<li>Writing strategies, Nielsen 1997.
<ul>
<li>Text more concise.</li>
<li>Text more scannable using subheadings, bullet lists, paragraphs.</li>
<li>Text more objective, less market-ese.</li>
<li>All are effective.</li>
</ul></li>
<li>Readings
<ul>
<li>User Interface Engineering, Designing for the Scent of Information.</li>
<li>Peter Pirolli, Information Foraging Theory.</li>
<li>Jakob Nielsen, Alertbox.</li>
</ul></li>
</ul>
<h3 id="design-studies-you-can-learn-from"><a href="#TOC">7.1: Design Studies You Can Learn From</a></h3>
<ul>
<li>Wrong: “Do you like my interface?”</li>
<li>Wrong: “How much do you like my interface?”</li>
<li>Please the experimenter bias, particularly with cultures with power differentials.</li>
<li>Developers are still valuable testers.</li>
<li>Need <em>specific measures</em> and <em>concrete questions</em>.</li>
<li><strong>Baserates</strong>: How often does Y occur? Measure Y.
<ul>
<li>What fraction of people click on this link?</li>
</ul></li>
<li><strong>Correlations</strong>: Do X and Y co-vary? Measure X and Y.
<ul>
<li>e.g. if people click on first search result, does that mean it’s a good search result or that they just click on the first thing they see?</li>
<li>Might need to randomise search results to determine causality.</li>
</ul></li>
<li><strong>Causes</strong>: Does X cause Y?
<ul>
<li>Measure X and Y, and manipulate X.</li>
<li>Somehow also account for effects of other confounding variables.</li>
</ul></li>
<li><strong>Independent variables</strong>: what we manipulate. Don’t depend on users.</li>
<li><strong>Dependent variables</strong>: what user does. e.g. task completion time, accuracy, recall, emotional response.</li>
<li><strong>Internal validity</strong>: how reliable? If you ran experiment again would you see the same results?</li>
<li><p><strong>External validity</strong>: generalizability. Do your results matter?</p></li>
<li>Is my cool new approach better than the industry standard?</li>
<li>Example - the user study of phone users, half physical QWERTY half physical numeric, using iPhones. They suck at it.
<ul>
<li>Manipulation: input style.</li>
<li>Measure: words per minute.</li>
<li>Benefit of study: absolutely want to measure if new technology is viable.</li>
<li>Drawback of study: beginners will always be poor at new technology. What happens when they become experts?</li>
<li>External validity: not so much.</li>
<li>A better version: actual users.</li>
<li>No surprise, users get much better and is about the same speed as physical QWERTY. However, iPhone users make more errors.</li>
</ul></li>
<li>Strategies for fairer comparisons
<ul>
<li>Insert your new approach into the production setting.
<ul>
<li>Even if no access to live server could use client-side scripting or proxy servers.</li>
</ul></li>
<li>Recreate the production approach in your new setting.</li>
<li>Scale things down so you’re just looking at a piece of a larger system.</li>
<li>When expertise is relevant, trains people up.</li>
</ul></li>
<li>Is interface X better than interface Y?
<ul>
<li>It depends.</li>
<li>More importantly, what does it depend on? What is measured, settings and context.</li>
</ul></li>
</ul>
<h3 id="assign-participants-to-conditions"><a href="#TOC">7.2: Assign Participants to Conditions</a></h3>
<ul>
<li><p>Should every participant use every alternative?</p></li>
<li>e.g. which is a better vacuum cleaner, automatic or traditional?
<ul>
<li>What are the measures?
<ul>
<li>Faster?</li>
<li>Cleaner?</li>
<li>Fatigue?</li>
<li>…</li>
</ul></li>
<li>Manipulation: vacuum type.</li>
<li>Measures: speed and type (focus on two).</li>
<li><strong>Between subjects design</strong>: assign half subjects to two different measures.
<ul>
<li>But with small smaple sizes difficult to tell if results are real.</li>
</ul></li>
<li><strong>Within subjects design</strong>: everyone uses all measures, both interfaces.
<ul>
<li>But what order to try them in? e.g. after trying manual vacuum cleaner you’re tired.</li>
</ul></li>
<li><strong>Counter-balancing</strong>: within subjects design with randomly assigned order.
<ul>
<li>Hopefully ordering effects balance out.</li>
<li>Also try to vary location for first and second trials, possible confounding variable.</li>
</ul></li>
</ul></li>
<li>How about individual differences? Shirt colour, shape of face?
<ul>
<li>If you think it has an impact then control for it.</li>
<li>Random assignment is usually best.</li>
</ul></li>
<li>What about three or more alternatives?
<ul>
<li><strong>Latin square</strong>. Randomly assign such that in each trial each option is chosen once, and for each participant they try all three options.</li>
</ul></li>
<li>The importance of random assignment.
<ul>
<li>e.g. typing in morning rather than afternoon. Which is faster?</li>
<li>If people come in as they wish and morning is faster that could just be because they’re morning people.</li>
<li>Hence randomly assign to time blocks.</li>
</ul></li>
<li><strong>Hawthorne effect</strong>
<ul>
<li>Manipulation: lighting levels in factory.</li>
<li>Measures: productivity.</li>
<li>Every manipulation increased productivity.</li>
<li>Conclusion: someone intervening skewed results.</li>
<li>Results are disputed.</li>
</ul></li>
<li><strong>Counterbalanced assignment</strong>
<ul>
<li>Identify potential confounding variables and assign participants accordingly.</li>
<li>e.g. if typing speed could affect interface usage, use pre-test to identify typing speed, then assign evenly across conditions.</li>
</ul></li>
<li><strong>Offline counterbalancing</strong>
<ul>
<li>Pre-test to measure confounding variable, e.g. typing speed.</li>
<li>Sort by variable.</li>
<li>For each pair in list flip a coin and choose one of the pair. Heads goes to first condition, tails to second.</li>
</ul></li>
<li><strong>Online counterbalancing</strong>
<ul>
<li>If you can’t pre-test pick some threshold that’s likely to be in the middle.</li>
</ul></li>
<li><p>Pre-test-like counter-balancing trying to make law of large numbers happen faster</p></li>
<li>Danger: regression to the mean.
<ul>
<li>With small sample sizes law of large numbers doesn’t have a chance to kick in.</li>
<li>Results just oscillating around mean.</li>
<li>Pre-test counterbalancing addresses this danger.</li>
</ul></li>
<li>Three major strategies.
<ul>
<li><strong>Within-subjects</strong>. Everyone tries all options. Good when not worried about learning / practice / exposure issues.</li>
<li><strong>Between-participants</strong>: each person tries one. Needs more people, more attention to fair assignment. Benefit: each participant is uncorrupted.
<ul>
<li>Most common.</li>
</ul></li>
<li>Use <strong>counterbalancing</strong> to minimize variation in a between-subjects design.</li>
</ul></li>
<li>Further reading
<ul>
<li>David Martin, “Doing Psychology Experiments”</li>
</ul></li>
</ul>
<h3 id="in-person-experiments"><a href="#TOC">7.3: In person experiments</a></h3>
<ul>
<li>Can talk to people, see what they’re doing and their confusion.</li>
<li><p>Higher bandwidth.</p></li>
<li><strong>Make clear goals</strong>. e.g. for online booking system.
<ul>
<li><strong>Scope</strong>: what we’re focusing on.</li>
<li><strong>Purpose</strong>: what you hope to learn.</li>
<li><strong>Hypothesis</strong>: what you want to test, should be testable.</li>
<li><strong>Schedule and location</strong>: choose appropriately. Quiet room? Train station?</li>
<li><strong>Participants</strong>: what type of people and how many?</li>
<li><strong>Scenarios</strong>: what you want users to try to accomplish. They must be able to care about this.</li>
<li><strong>Questions to ask</strong>.</li>
<li><strong>Data to be collected</strong>. e.g. task completion, error rate.</li>
<li><strong>Experimenter roles</strong>. Try to have at least two people, one facilitator and one note taker.</li>
</ul></li>
<li>e.g. for online booking system:
<ul>
<li>Scope: make meeting room booking system.</li>
<li>Purpose: create system that encourage people to book right sized room for right duration.</li>
<li>Hypothesis: splitting up booking process encourages more thought and works better.</li>
</ul></li>
<li><strong>Create concrete tasks</strong>. Write them down.</li>
<li><strong>Ethical considerations</strong>.
<ul>
<li>Make consent voluntary. Don’t pressure people to participate.</li>
<li>Remind people: you’re testing the site, not them.</li>
</ul></li>
<li><strong>Experimental details</strong>.
<ul>
<li><em>Order of tasks</em>? Easy to hard? Random?</li>
<li><em>Training</em>? Ticket machine vs. surgical machine.</li>
<li><em>Do not finish</em>? Upper bounds for time, small stumbling blocks =&gt; nudge them.</li>
<li><em>Pilot study</em>: work out kinks in experiment itself.
<ul>
<li>Recommend having two pilot studies. One with colleague to figure out material needed and tasks. A second with one real user.</li>
</ul></li>
</ul></li>
<li><strong>Capturing results</strong>.
<ul>
<li>At least a notebook or a computer.</li>
<li>Maybe record video.</li>
<li>Screen recording.</li>
</ul></li>
<li><strong>Think-aloud method</strong>.
<ul>
<li>Need to know what users are thinking, not just doing.</li>
<li>Ask users while they’re performing tasks:
<ul>
<li>What they are thinking</li>
<li>What they are trying to do.</li>
<li>What questions they have.</li>
<li>What they read.</li>
</ul></li>
<li>Prompt users to keep talking. “Tell me what you are thinking”. Avoid specific questions.</li>
<li>Only help on things you’ve pre-decided to, write this down.</li>
<li>Record with watch and notes.</li>
</ul></li>
<li>Study steps.</li>
<li>Greeting participants - explain study, show setup.</li>
<li>Collecting data.
<ul>
<li>Process data, observations, more qualitative.</li>
<li>Bottom-line data.
<ul>
<li>Summaries of time, did they succeed, number of errors. Quantitative.</li>
<li>i.e. dependent variables.</li>
</ul></li>
<li>Define errors or what success means ahead of time.</li>
<li>Do not combine thinking aloud with bottom-line data.
<ul>
<li>Talking can affect speed and accuracy.</li>
</ul></li>
</ul></li>
<li>Debrief them at the end.
<ul>
<li>Get their holistic last impressions.</li>
<li>Tell them what they’ve contributed to.</li>
</ul></li>
</ul>
<h3 id="a-running-web-experiments-1"><a href="#TOC">7.4a: Running Web Experiments (1)</a></h3>
<ul>
<li>A/B testing.
<ul>
<li>A: old version, B: potential new version</li>
<li>Generalisable to multiple tests, randomly assign.</li>
<li>Collect metrics on specific goals; click throughs, sales, etc.</li>
</ul></li>
<li>Web makes it easy to prototype and rapidly try new designs.</li>
<li>Why did multiple columns reduce sales by half for National Alert Registry?
<ul>
<li>For sales maybe want one clear funnel of activity, not ambiguous options.</li>
</ul></li>
<li>Small differences make big changes, e.g.
<ul>
<li>Position and color of primary call to action.</li>
<li>Position of testimonials.</li>
<li>White space?</li>
<li>What is linked?</li>
<li>Number of columns? Number of different elements?</li>
</ul></li>
<li>Metrics for email shots, number of:
<ul>
<li>Opened, click throughs, forwards.</li>
</ul></li>
<li>Obama sign up campaign.
<ul>
<li>Button text: “sign up”, “learn more”, “sign up now”, “join us now”.</li>
<li>Videos worse than images.</li>
<li>Small changes, big differences.</li>
<li>Our expectations are often wrong.</li>
</ul></li>
</ul>
<h3 id="b-running-web-experiments-2"><a href="#TOC">7.4b: Running web experiments (2)</a></h3>
<ul>
<li>Be clear what you want from users, e.g. not “I’m on Twitter” but “You should follow me on Twitter here”.</li>
<li><em>Even small changes have detectable differences.</em></li>
<li>Beware confounding factors; weekend, daylight savings switch.</li>
<li>Randomness helps imply causality rather than correlation.</li>
<li>“Expedia on how one extra data field can cost $12m”.
<ul>
<li>Just added their company name.</li>
</ul></li>
<li>Microsoft feedback.
<ul>
<li>After stars rating revealing text box 50% better than statically showing text box.</li>
<li>Fewer buttons in feedback form increases feedback by factor of 3.5.</li>
</ul></li>
<li><strong>Commitment escalation</strong>: get user to do a little bit, and then a little bit more. Better than asking for a lot up front.
<ul>
<li>Subtle, requires fine tuning.</li>
<li>Hence needs iterative design and experimentation.</li>
</ul></li>
</ul>
<h3 id="c-running-web-experiments-3"><a href="#TOC">7.4c: Running web experiments (3)</a></h3>
<ul>
<li>Principles for Effective Online Experiments.</li>
<li>Equal probability in each variant <em>in the long run</em>.
<ul>
<li>Ramp up. Start experiment at 0.1%. Helps prevent disasters.</li>
<li>Automatically abort bad experiments.</li>
</ul></li>
<li>Don’t just run experiments on dependent variables that are easy to measure. Run experiments on variables that matter.</li>
<li>Run changes for long enough to allow them to become familiar with it.</li>
<li>Rules for random assignment:
<ul>
<li><strong>Consistent</strong>. Same person sees same variant on each login.
<ul>
<li>Else users will perceive interface to be random.</li>
</ul></li>
<li><strong>Durable</strong>.</li>
<li><strong>Independent</strong>. Make sure assignment is truly random, not dependent on e.g. day of the week.</li>
</ul></li>
<li>Even with data theorising why the changes matter is still hard.</li>
<li>Use multiple methods to help build theories, e.g. web experiements, in-person studies.</li>
<li>Design in the online age
<ul>
<li>Rather than one great design, now many alternatives.</li>
<li>Rapid experimentation, helps quickly test assumptions.</li>
</ul></li>
</ul>
<h3 id="comparing-rates"><a href="#TOC">6.5: Comparing rates</a></h3>
<ul>
<li>Three questions
<ol style="list-style-type: decimal">
<li><pre><code>**What does my data look like?**</code></pre>
<ul>
<li>Visualisations, summaries, plot.</li>
</ul></li>
<li><pre><code>**What are the overall numbers?*8</code></pre>
<ul>
<li>Aggregate statistics, mean and standard deviations.</li>
</ul></li>
<li><pre><code>**Are the differences &quot;real&quot;?**</code></pre>
<ul>
<li>Significace, p values.</li>
<li>Likelihood results are due to chance.</li>
</ul></li>
</ol></li>
<li><strong>Test statistic</strong>, how unexpected is result.</li>
<li><strong>Pearson’s Chi-Squared Test</strong>.
<ul>
<li><p>Compare observed to expected, taking into account number of trials.</p>
<pre><code>chi^2 = (observed - expected) ^ 2 / expected</code></pre></li>
<li>“Normal” outcome variance, Gaussian.
<ul>
<li>p = 0.05 means observation in the tails.</li>
</ul></li>
<li><strong>The Null Hypothesis</strong>: opening assumption is “we don’t think there is any difference between observation and expection”.</li>
<li>Critical Values for Chi-Squared. p value vs. chi^2 value. Bigger chi^2 =&gt; smaller p.</li>
</ul></li>
<li><strong>Degrees of freedom</strong>: (number of choices - 1).</li>
<li>Statistical testing:
<ul>
<li>Formalizes “we’re pretty sure”.</li>
<li>Helps generalize (or not) from small samples.</li>
</ul></li>
<li>Guiness beer.
<ul>
<li>Student’s t-test created for testing quality of stout.</li>
<li>If testing consumed all beer then not cost-effective!</li>
<li>Also, statisticians find math more difficult after drinking a lot of beer.</li>
</ul></li>
<li>For continuous data:
<ul>
<li>T-tests (compare 2 conditions)</li>
<li>ANOVA (compare &gt;2 conditions).</li>
<li>Both for normally distributed data.</li>
</ul></li>
<li>Data often isn’t “normal”
<ul>
<li>Bi-modal, two maxima.</li>
<li>Skewed, e.g. response rates as time.</li>
</ul></li>
<li>Handling non-normal data:
<ul>
<li>Knowing is half the battle.</li>
<li>A/A test. Split users in half and expose to same variant. Any significance?</li>
<li>Use randomized testing. Repeated simulations to model data. Not covered.</li>
</ul></li>
<li><em>Graph all the data!</em></li>
<li><em>Use statistical testing.</em></li>
<li>Further reading
<ul>
<li>Practical Statistics for HCI, Jacob Wobbrock, http://depts.washington.edu/aimgroup/proj/ps4hci</li>
<li>Doing Psychology Experiments, David W. Martin</li>
<li>Statistics as Principled Argument, Robert P. Abelson</li>
<li>Learning to use statistical tests in psychology, Judith Greene, Manuela D’Oliveira.</li>
</ul></li>
</ul>
<h4 id="readings"><a href="#TOC">Readings:</a></h4>
<ul>
<li><p>3.1 and assignment 2, Prototyping</p></li>
<li>10 Heuristics for User Interface Design
<ol style="list-style-type: decimal">
<li><strong>Visibility of system status</strong>.
<ul>
<li>Users informed of what is going in.</li>
<li>Appropriate and prompt.</li>
</ul></li>
<li><strong>Match between system and real world</strong>.
<ul>
<li>Speak user’s language.</li>
<li>Follow real-world conventions.</li>
<li>Natural and logical.</li>
</ul></li>
<li><strong>User control and freedom</strong>.
<ul>
<li>Mistakes happen, need undo and redo.</li>
</ul></li>
<li><strong>Consistency and standards</strong>.
<ul>
<li>Follow conventions.</li>
</ul></li>
<li><strong>Error prevention</strong>.
<ul>
<li>Eliminate error-prone conditions or check for them.</li>
<li>Confirmation of action commits.</li>
</ul></li>
<li><strong>Recognition rather than recall</strong>.
<ul>
<li>Instructions and options should be visible and easily retrievable.</li>
</ul></li>
<li><strong>Flexibility and efficiency of use</strong>.
<ul>
<li>Experts need accelerators, novices can ignore them.</li>
<li>Allow users to tailor frequent actions.</li>
</ul></li>
<li><strong>Aesthetic and minimalist design</strong>.
<ul>
<li>Remove irrelevant or rarely needed information.</li>
</ul></li>
<li><strong>Help users recognize, diagnose, and recover from errors</strong>.
<ul>
<li>Plain language.</li>
<li>Explain problem and suggest solution.</li>
</ul></li>
<li><strong>Help and documentation</strong>.
<ul>
<li>Better that system is usable without docs.</li>
<li>But docs should exist, easy to search, focused on user’s task, concrete.</li>
</ul></li>
</ol></li>
</ul>
<h2 id="assignment-notes"><a href="#TOC">Assignment notes</a></h2>
<h2 id="general-notes"><a href="#TOC">General notes</a></h2>
</body>
</html>
