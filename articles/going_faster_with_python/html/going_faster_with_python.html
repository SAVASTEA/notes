<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title></title>
  <style type="text/css">code{white-space: pre;}</style>
  <style type="text/css">
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; }
code > span.dt { color: #902000; }
code > span.dv { color: #40a070; }
code > span.bn { color: #40a070; }
code > span.fl { color: #40a070; }
code > span.ch { color: #4070a0; }
code > span.st { color: #4070a0; }
code > span.co { color: #60a0b0; font-style: italic; }
code > span.ot { color: #007020; }
code > span.al { color: #ff0000; font-weight: bold; }
code > span.fu { color: #06287e; }
code > span.er { color: #ff0000; font-weight: bold; }
  </style>
  <script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
  <link href='http://fonts.googleapis.com/css?family=Noticia+Text:400,400italic,700,700italic&subset=latin,latin-ext' rel='stylesheet' type='text/css'>
  <link href='http://fonts.googleapis.com/css?family=Source+Sans+Pro:400,700,400italic,700italic&subset=latin,latin-ext' rel='stylesheet' type='text/css'>
  <link href='http://fonts.googleapis.com/css?family=Inconsolata:400,700&subset=latin,latin-ext' rel='stylesheet' type='text/css'>
  
  <link rel="stylesheet" href="bootstrap-app.css" type="text/css" />
  <link rel="stylesheet" href="custom.css" type="text/css" />
  
</head>
<body>
<h1 id="going-faster-with-python"><a href="#going-faster-with-python">Going Faster with Python</a></h1>
<p><a rel="license" href="http://creativecommons.org/licenses/by-sa/3.0/deed.en_US"><img alt="Creative Commons License" style="border-width:0" src="http://i.creativecommons.org/l/by-sa/3.0/88x31.png" /></a><br /><span xmlns:dct="http://purl.org/dc/terms/" href="http://purl.org/dc/dcmitype/Text" property="dct:title" rel="dct:type">Going Faster With Python</span> by <a xmlns:cc="http://creativecommons.org/ns#" href="http://www.asimihsan.com" property="cc:attributionName" rel="cc:attributionURL">Asim Ihsan</a> is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/3.0/deed.en_US">Creative Commons Attribution-ShareAlike 3.0 Unported License</a>.</p>
<iframe src="http://tools.flattr.net/widgets/thing.html?thing=1150097" width="292" height="250"></iframe>

<h2>Table of contents</h2>
<div id="TOC">
<ul>
<li><a href="#going-faster-with-python">Going Faster with Python</a><ul>
<li><a href="#revision-history">Revision History</a></li>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#part-1---when-do-i-optimise">Part 1 - When Do I Optimise?</a></li>
<li><a href="#part-2---how-do-i-know-where-to-optimise">Part 2 - How Do I Know Where To Optimise?</a><ul>
<li><a href="#basic-timing">Basic timing</a></li>
<li><a href="#logging">Logging</a></li>
<li><a href="#cpu-profiling">CPU profiling</a></li>
<li><a href="#memory-profiling">Memory profiling</a></li>
</ul></li>
<li><a href="#part-3---how-do-i-optimise">Part 3 - How Do I Optimise?</a><ul>
<li><a href="#introduction-1">Introduction</a></li>
<li><a href="#cpython-and-bytecode-analysis">CPython and Bytecode Analysis</a></li>
<li><a href="#cython">Cython</a></li>
<li><a href="#numpy">numpy</a></li>
<li><a href="#cython-with-numpy">Cython with numpy</a></li>
<li><a href="#pypy">PyPy</a></li>
</ul></li>
<li><a href="#part-4---case-study-1---a-log-parser">Part 4 - Case Study 1 - A Log Parser</a><ul>
<li><a href="#introduction-2">Introduction</a></li>
<li><a href="#use-cases">Use Cases</a></li>
<li><a href="#initial-code">Initial Code</a></li>
<li><a href="#initial-profiling">Initial Profiling</a></li>
</ul></li>
<li><a href="#part-5---case-study-2---n-gram-language-models">Part 5 - Case Study 2 - N-gram Language Models</a><ul>
<li><a href="#introduction-3">Introduction</a></li>
<li><a href="#use-cases-1">Use Cases</a></li>
<li><a href="#initial-code-1">Initial Code</a></li>
<li><a href="#initial-profiling-1">Initial Profiling</a></li>
</ul></li>
<li><a href="#references">References</a></li>
</ul></li>
</ul>
</div>
<h2 id="revision-history"><a href="#revision-history">Revision History</a></h2>
<ul>
<li><strong>2013-02-24</strong> - first draft.</li>
</ul>
<h2 id="introduction"><a href="#introduction">Introduction</a></h2>
<p>This article is about optimisation in Python. <strong>Optimisation</strong> is seeking to minimise the usage of some resource during the execution of a software system. Although commonly synonymous with minimising execution time I’ll also be covering minimising memory occupancy.</p>
<ul>
<li>In a break from many articles in this vein, part 1 will ask what role optimisation plays in the software development process and under what conditions optimisation is even an appropriate action.</li>
<li>Part 2 will cover techniques for measuring both the execution time and memory occupancy of Python programmes.</li>
<li>Part 3 details, and may serve as a reference for, a myriad of methods for optimisation in Python. All of them are illustrated with toy examples.</li>
<li>Parts 4 and 5 are another break from most articles in that, rather than relegate ourselves to toy micro-benchmarks, I’ll be covering two real-world Python applications and their profiling and optimisation.</li>
</ul>
<p>This article’s target audience is intermediate-level Python and beginner-level C developers; you’ve written non-trival code in Python before and can compile and run a “Hello World!” example in C.</p>
<p>Although the article’s primary focus is optimising to reduce the execution time of Python programmes it will restrict itself to single-process optimisations; parallelising tasks both on a multicore system using e.g. multiprocessing<span class="citation"><sup><a href="#fn1" class="footnoteRef" id="fnref1">1</a></sup></span> and onto many systems using e.g. celery<span class="citation"><sup><a href="#fn2" class="footnoteRef" id="fnref2">2</a></sup></span> or ParallelPython<span class="citation"><sup><a href="#fn3" class="footnoteRef" id="fnref3">3</a></sup></span> is a topic worthy of its own article.</p>
<h2 id="part-1---when-do-i-optimise"><a href="#part-1---when-do-i-optimise">Part 1 - When Do I Optimise?</a></h2>
<blockquote>
<p>“Programmers waste enormous amounts of time thinking about, or worrying about, the speed of noncritical parts of their programs, and these attempts at efficiency actually have a strong negative impact when debugging and maintenance are considered. <strong>We should forget about small efficiencies</strong>, say about 97% of the time: premature optimization is the root of all evil. <strong>Yet we should not pass up our opportunities in that critical 3%</strong>.” –Donald Knuth<span class="citation"><sup><a href="#fn4" class="footnoteRef" id="fnref4">4</a></sup></span></p>
</blockquote>
<p>If we know software needs to be fast then why can’t we code with this perspective front-and-centre at all times?</p>
<p>There are many problems with statement, the first being: how fast? The best way to achieve performance requirements is to associate it with precise, quantifiable, and measureable metrics.<span class="citation"><sup><a href="#fn5" class="footnoteRef" id="fnref5">5</a></sup></span> In this case examples would be:</p>
<ul>
<li>“the time to first byte (TTFB) for the software service will be 200ms for 95% of all requests”, or</li>
<li>“CPU usage will never exceed 65%”</li>
</ul>
<p>In some environments, such as hard real-time operating system components or mission-critical command-and-control servers, these are reasonable requirements. In others, such as a personal blog, they would be patently ridiculous. Context matters.</p>
<p>Another problem with the “omnipresent” approach is that there is no free lunch. There are many characteristics of a good software implementation, of which performance is only one,<span class="citation"><sup><a href="#fn6" class="footnoteRef" id="fnref6">6</a></sup></span>.<span class="citation"><sup><a href="#fn7" class="footnoteRef" id="fnref7">7</a></sup></span> In no particular order some are:</p>
<ul>
<li><strong>Readability</strong>: can be easily read and understood.</li>
<li><strong>Maintainability</strong>: can be easily modified, extended, and maintained.</li>
<li><strong>Performance</strong>: minimises any one, or all of, execution time, memory usage, and power consumption.</li>
<li><strong>Correctness</strong>: does what it is specified to do.</li>
<li><strong>Completeness</strong>: all the requirements are met.</li>
</ul>
<p>As you prioritise some of the above properties you must sacrifice attention to others. An absolute focus on performance must necessarily come at the cost of, for example, readability and maintainability.</p>
<p>Even if your software system places a premium on performance it is a fallacy to suggest that this may only be addressed at the code tuning level. You have many options, at many stages:<span class="citation"><sup><a href="#fn8" class="footnoteRef" id="fnref8">8</a></sup></span></p>
<ul>
<li><strong>Program requirements</strong>:
<ul>
<li>Do your users actually require this level of performance? What do they need?</li>
<li>Users typically don’t directly care about latency and throughput and instead care about time elapsed to execute use cases. Have you considered your user interface, user experience, and information architecture?</li>
</ul></li>
<li><strong>Program design</strong>
<ul>
<li>Set resource objectives for individual sub-components and interfaces, and track them proactively.</li>
<li>Set goals that may achieve performance objectives indirectly in the future. If you aim for highly modular and modifiable code then, as your system enters end-to-end use, you can easily swap out slow components for better implementations.</li>
</ul></li>
<li><strong>Class and routine design</strong>
<ul>
<li>Choose appropriate algorithms and data structures<span class="citation"><sup><a href="#fn9" class="footnoteRef" id="fnref9">9</a></sup></span> at the beginning.</li>
</ul></li>
<li><strong>Hardware</strong>
<ul>
<li>Is buying more or faster hardware more cost-effective than the employee time required to tune the code?</li>
</ul></li>
</ul>
<p>There is a third, and perhaps the most counter-intuitive, problem with constant optimization throughout coding. It is not only a standard heuristic but a repeatedly verified observation that software systems tend to spend <strong>most of their execution time in a minority of their code</strong>.</p>
<ul>
<li>Knuth, in a survey of FORTRAN programmes, discovered that not only are maintainability and readability more desireable properties for programmes than performance but most FORTRAN programmes spent the majority of their time in a small number of code locations.<span class="citation"><sup><a href="#fn10" class="footnoteRef" id="fnref10">10</a></sup></span></li>
<li>Patterson and Hennsey note that software programmes, as a rule of thumb, spend 90% of their time in 10% of their code, and also exhibit <strong>temporal locality</strong>, where recently accessed memory and code tend to be accessed soon again,.<span class="citation"><sup><a href="#fn11" class="footnoteRef" id="fnref11">11</a></sup></span></li>
</ul>
<p>Given that programs spend the majority of their time in a minority of their code, constantly optimizing everything, in the best case, is mostly wasted! This “execution locality”, and how it impacts optimisation, is expressed in <strong>Amdahl’s Law</strong>,<span class="citation"><sup><a href="#fn12" class="footnoteRef" id="fnref12">12</a></sup></span> which describes how the total speedup of a software system after speeding up a constituent subcomponent depends on what fraction of the total time the subcomponent takes up:</p>
<p><span class="math">\[
\begin{align}
    &amp;\begin{aligned}
        \textrm{Execution time}_{\textrm{old}} &amp; = \textrm{Execution time}_{\textrm{new}} \times \left( \left( 1 - \textrm{Fraction}_{\textrm{enhanced}} \right) + \frac{ \textrm{Fraction}_{\textrm{enhanced}}}{\textrm{Speedup}_{\textrm{enhanced}}} \right) \\
        \textrm{Speedup}_{\textrm{overall}} &amp; = \frac{\textrm{Execution time}_{\textrm{old}}}{\textrm{Execution time}_{\textrm{new}}} \\
        &amp; = \frac{1}{ \left( 1 - \textrm{Fraction}_{\textrm{enhanced}} \right) + \frac{ \textrm{Fraction}_{\textrm{enhanced}}}{\textrm{Speedup}_{\textrm{enhanced}}}}
    \end{aligned}
\end{align}
\]</span></p>
<p>Here’s an example. Suppose we have a web server and there is a routine we could optimise such that it becomes 10 times faster. Assuming that the web server process is busy with with this routine 40% of the time what is the overall speedup after the optimisation?</p>
<p><span class="math">\[
\begin{align}
    &amp;\begin{aligned}
        \textrm{Fraction}_{\textrm{enhanced}} &amp; = 0.4 \\
        \textrm{Speedup}_{\textrm{enhanced}} &amp; = 10 \\
        \textrm{Speedup}_{\textrm{overall}} &amp; = \frac{1}{(1-0.4) + \frac{0.4}{10}} \\
        &amp; = \frac{1}{0.64} \\
        &amp; = \textrm{1.56 (3dp)}
    \end{aligned}
\end{align}
\]</span></p>
<p>Indeed, by Amdahl’s Law, the maximum possible speedup of the software system is <span class="math">\(\frac{1}{0.6} = \textrm{1.67 (3dp)}\)</span>.</p>
<p>In short: software optimisation is often best achieved during the requirements analysis and component design stages, but the time will come when you can’t shy away from a performance problem. At this point the next step is determining what is slow, and not just jumping into coding; this is part 2.</p>
<p>In parting I’ll leave you with this:</p>
<blockquote>
<p>“If there’s a moral to this story, it is this: do not let performance considerations stop you from doing what is right. You can always make the code faster with a little cleverness. You can rarely recover so easily from a bad design…<strong>Design the program you want in the way it should be designed. Then, and only then, should you worry about performance</strong>. More often than not, you’ll discover the program is fast enough on your first pass.” –Elliotte Rusty Harold<span class="citation"><sup><a href="#fn13" class="footnoteRef" id="fnref13">13</a></sup></span></p>
</blockquote>
<h2 id="part-2---how-do-i-know-where-to-optimise"><a href="#part-2---how-do-i-know-where-to-optimise">Part 2 - How Do I Know Where To Optimise?</a></h2>
<p>If Part 1 is “how fast?”, part 2, in an extraordinary leap of atrocious grammar, is “where slow?”. Your software architecture is modular with well-defined interfaces, you’ve defined precise, quantifiable, and measureable performance metrics, and lo and behold you’re not meeting them after implementing a significant portion of tested functionality. Now what?</p>
<h3 id="basic-timing"><a href="#basic-timing">Basic timing</a></h3>
<p>Particularly if you’re looking at system command-line utilities or scientific computing simply knowing “how much time did this take to finish?” or “how much RAM did it use at its peak?” is a good first step.</p>
<p>Typical approaches to doing this use <code>top</code> and <code>time</code>, and are very simple effective. Often however people forget that measurements must be repeated in order to gain confidence as to their accuracy. Hence to help you get started I’ve created a noddy little script for this article, <code>src/utilities/measureproc.py</code>.<span class="citation"><sup><a href="#fn14" class="footnoteRef" id="fnref14">14</a></sup></span></p>
<p>Let’s assume we using this little toy script:</p>
<table class="sourceCode python numberLines"><tr class="sourceCode"><td class="lineNumbers"><pre>1
2
3
4
5
6
7
8
</pre></td><td class="sourceCode"><pre><code class="sourceCode python"><span class="co">#!/usr/bin/env python</span>

<span class="ch">import</span> time

<span class="kw">if</span> <span class="dt">__name__</span> == <span class="st">&quot;__main__&quot;</span>:
    a = <span class="dt">range</span>(<span class="dv">2</span> ** <span class="dv">24</span>)
    <span class="kw">print</span> a[-<span class="dv">1</span>]
    time.sleep(<span class="dv">1</span>)</code></pre></td></tr></table>
<p>In order to make repeated measurements as to its CPU and memory usage:</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">(</span>going_faster_with_python<span class="kw">)</span>Mill:going_faster_with_python ai$ <span class="kw">pwd</span>
/Users/ai/Programming/going_faster_with_python

<span class="kw">(</span>going_faster_with_python<span class="kw">)</span>Mill:going_faster_with_python ai$ python src/utilities/measureproc.py
python src/utilities/longscript.py
Summary of 5 runs
metric  <span class="kw">|</span> min    <span class="kw">|</span> Q1     <span class="kw">|</span> median <span class="kw">|</span> Q2     <span class="kw">|</span> max   
--------+--------+--------+--------+--------+-------
clock   <span class="kw">|</span> 1.96   <span class="kw">|</span> 1.97   <span class="kw">|</span> 1.98   <span class="kw">|</span> 1.97   <span class="kw">|</span> 2.08  
user    <span class="kw">|</span> 0.68   <span class="kw">|</span> 0.68   <span class="kw">|</span> 0.68   <span class="kw">|</span> 0.68   <span class="kw">|</span> 0.76  
system  <span class="kw">|</span> 0.22   <span class="kw">|</span> 0.22   <span class="kw">|</span> 0.22   <span class="kw">|</span> 0.22   <span class="kw">|</span> 0.25  
rss_max <span class="kw">|</span> 525.39 <span class="kw">|</span> 525.39 <span class="kw">|</span> 525.39 <span class="kw">|</span> 525.39 <span class="kw">|</span> 525.39</code></pre>
<p>The script outputs four important metrics:</p>
<ul>
<li><strong>clock</strong> (s): how much time elapsed between the start and end of the program. You’ll note that the median clock time is approximately two seconds.</li>
<li><strong>user</strong> (s): how much time spent by the CPU in the <strong>user space</strong>, i.e. in your script’s code.</li>
<li><strong>system</strong> (s): how much time spent by the CPU in the <strong>kernel space</strong>, i.e. executing code within the lower levels of the operating system.</li>
<li><strong>rss_max</strong> (MB): the peak amount of memory allocated for the program’s <strong>Resident Set Size</strong> (RSS), i.e. the memory allocated within physical memory, as opposed to the <strong>Virtual Memory Size</strong> (VMS).</li>
</ul>
<p>The script summarises the measurements of these metrics over N runs using:</p>
<ul>
<li><strong>min</strong>: the minimum value.</li>
<li><strong>Q1</strong>: the 25% percentile, i.e. 25% of values are equal or less than this value.</li>
<li><strong>median</strong>: the 50% percentile.</li>
<li><strong>Q2</strong>: the 75% percentile.</li>
<li><strong>max</strong>: the maximum value.</li>
</ul>
<p>We note the following observations:</p>
<ul>
<li><span class="math">\((Q2 - Q1)\)</span> for all metrics is very small. The measurements are consistent over time and the results are readily reproducible.</li>
<li>The median clock time is 2 seconds. The user’s perception of the programme is that it took two seconds to execute.</li>
<li>The sum of the user and system times is approximately 0.9 seconds. This means that <span class="math">\(2 - 0.9 = 1.1\)</span> seconds was spent waiting for I/O operations. This script spent half its time using the CPU and half its time waiting.</li>
<li>The sum of the above two observations is that perhaps one second was spent allocating memory for the array and one second was spent sleeping.</li>
<li>The RSS max is approximately 525MB. This is rather large!</li>
</ul>
<h3 id="logging"><a href="#logging">Logging</a></h3>
<p>The humblest yet most important of approaches, <strong>logging</strong> is an old friend to most of us. In fact some of you may be thinking “Why am I even bothering with this article? Everyone knows that configurable tracing is critical in any production system.”. Although logging isn’t the focus of this article I wanted to cover some quick points regarding it.</p>
<ul>
<li>Use <strong>discipline</strong> when applying logging calls to you code. As a rule of thumb:
<ul>
<li>All <em>function entries and exits</em> should be traced by a log of the lowest severity type. Function entries also within reason trace their <em>arguments</em>.</li>
<li>All <em>branches</em>, for example following an if statement, an else statement, a try statement, a finally statement, etc., should be traced by a log of at least the lowest severity type.</li>
<li>All <em>exceptions</em> are logged either with e.g. <code>logging.exception</code><span class="citation"><sup><a href="#fn15" class="footnoteRef" id="fnref15">15</a></sup></span> to log the stack of the failure, or using a package like <code>sentry</code>.<span class="citation"><sup><a href="#fn16" class="footnoteRef" id="fnref16">16</a></sup></span></li>
<li>All potentially <em>long-running tasks</em> are wrapped in logging statements immediately preceding and following them. This is especially true for tasks involving external interfaces or tasks with tightly defined performance requirements (you have those, right?).</li>
</ul></li>
<li>Logs are far more valuable when they’re <strong>collected</strong>, <strong>parsed</strong>, and <strong>analysed</strong>.
<ul>
<li>With end-to-end solutions like <code>logstash</code><span class="citation"><sup><a href="#fn17" class="footnoteRef" id="fnref17">17</a></sup></span> becoming more common there’s little excuse leaving your poor logs sitting alone in the corner.</li>
</ul></li>
</ul>
<p>With such discipline, in time forming habit, you can react quite effectively to a wide variety of inquiries, such as:</p>
<ul>
<li>“Well, most of the time this page is fine, but when a new user searches for”foo bar’s excellent bizz&quot; from their empty profile page everything grinds to a halt!&quot;</li>
<li>“When I search for ‘2013/01/43 19:00’ as a start datetime the server reaches 100% CPU usage, runs out of memory, then kernel panics.” (This happened to me in a legacy system I inherited, true story).</li>
</ul>
<p>For Django fans <code>django-debug-toolbar</code><span class="citation"><sup><a href="#fn18" class="footnoteRef" id="fnref18">18</a></sup></span> helps tie together the behaviour of Django components throughout the request cycle, including SQL queries and time taken to execute them.</p>
<h4 id="pycounter"><a href="#pycounter">PyCounter</a></h4>
<p>TODO</p>
<p>Decorator that records frequency and time spent for individual functions.</p>
<p>To install: <code>pip install pycounters</code>.</p>
<p>To use:</p>
<ul>
<li><code>from pycounters.shortcuts import frequency, time</code></li>
<li>Set up a log reporter:</li>
</ul>
<table class="sourceCode python numberLines"><tr class="sourceCode"><td class="lineNumbers"><pre>1
2
3
4
5
6
</pre></td><td class="sourceCode"><pre><code class="sourceCode python"><span class="ch">import</span> pycounters
<span class="ch">import</span> logging

reporter=pycounters.reporters.LogReporter(logging.getLogger(<span class="st">&quot;counters&quot;</span>))
pycounters.register_reporter(reporter)
pycounters.start_auto_reporting(seconds=<span class="dv">300</span>)</code></pre></td></tr></table>
<ul>
<li>Decorate functions with <code>@frequency()</code> and <code>@time()</code>.</li>
</ul>
<p>For more information see.<span class="citation"><sup><a href="#fn19" class="footnoteRef" id="fnref19">19</a></sup></span></p>
<h3 id="cpu-profiling"><a href="#cpu-profiling">CPU profiling</a></h3>
<p>Detailed logging, and coming up with efficient and useful toolchains for analysing them, can be a chore sometimes. Fortunately, particularly if you’re dealing with smaller command-line-based tools or scientific computing, <strong>CPU profiling</strong> is another option.</p>
<p>In CPU profiling you gather information about function call chains (who calls whom) and how long functions take to return. There are two types of CPU profiling methods:</p>
<ol style="list-style-type: decimal">
<li><strong>Deterministic profiling</strong>. Your measurements are comprehensive, in that you record every single function call at the greatest possible precision. If the effort of such measurement <em>does not impede the actual functionality</em> of the softare system this method is fine, but this is a big assumption.</li>
<li><strong>Statistical profiling</strong>. Your measurements are sporadic but regular, with a configurable interval. By being sporadic the hope is that you have less, and hopefully negligible, impact on the actual functionality of the software system, at the cost of less precise measurements.</li>
</ol>
<p>Let’s run through a variety of CPU profilers with a toy example.</p>
<h4 id="our-toy-example"><a href="#our-toy-example">Our toy example</a></h4>
<p>Let’s assume there is a BZIP2 compressed log file that we want to parse, and that each line is a measurement of a metric in the format <code>epoch, metric name, metric value</code>, e.g.:</p>
<pre><code>1362330056,cpu_usage,112
1362330057,cpu_usage,21
...</code></pre>
<p>Our objective is to determine the arithmetic mean of the <code>cpu_usage</code> values throughout the whole file.</p>
<p>I’ve created a script <code>src/utilities/generate_log.py</code><span class="citation"><sup><a href="#fn20" class="footnoteRef" id="fnref20">20</a></sup></span> that will generate a log in this format into the path <code>src/utilities/example.log.bz2</code>. Please run this script before continuing.</p>
<p>In order to parse this script we’re using <code>src/cpu_profiling/parse_log.py</code>.<span class="citation"><sup><a href="#fn21" class="footnoteRef" id="fnref21">21</a></sup></span> It has shown poor performance and we want to see what parts are slow (I’ve deliberately made this script very non-idiomatic and obtuse in places. This is <em>not</em> an example of good code! Unsurprising considering the context):</p>
<table class="sourceCode python numberLines"><tr class="sourceCode"><td class="lineNumbers"><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
</pre></td><td class="sourceCode"><pre><code class="sourceCode python"><span class="co">#!/usr/bin/env python</span>

<span class="ch">from</span> <span class="dt">__future__</span> <span class="ch">import</span> division

<span class="ch">import</span> os
<span class="ch">import</span> sys
<span class="ch">import</span> bz2
<span class="ch">import</span> contextlib
<span class="ch">import</span> re

<span class="co"># -------------------------------------------------------------------</span>
<span class="co">#   Constants.</span>
<span class="co"># -------------------------------------------------------------------</span>
current_dir = os.path.abspath(os.path.join(<span class="ot">__file__</span>, os.pardir))
parent_dir = os.path.join(current_dir, os.pardir)
log_filepath = os.path.join(parent_dir, <span class="st">&quot;utilities&quot;</span>, <span class="st">&quot;example.log.bz2&quot;</span>)

re_log_line = re.<span class="dt">compile</span>(<span class="st">&quot;(.*?),(.*?),(.*)</span><span class="ch">\n</span><span class="st">&quot;</span>)
<span class="co"># -------------------------------------------------------------------</span>

<span class="kw">def</span> main():
    cpu_usages = []
    <span class="kw">with</span> contextlib.closing(bz2.BZ2File(log_filepath)) <span class="ch">as</span> f_in:
        <span class="kw">for</span> line in f_in:
            process_line(line, cpu_usages)
    summarise(cpu_usages)

<span class="kw">def</span> summarise(cpu_usages):
    <span class="kw">print</span> <span class="st">&quot;avg: </span><span class="ot">%s</span><span class="st">&quot;</span> % (<span class="dt">sum</span>(cpu_usages) / <span class="dt">len</span>(cpu_usages), )

<span class="kw">def</span> process_line(line, cpu_usages):
    re_obj = re_log_line.search(line)
    <span class="kw">try</span>:
        elems = re_obj.groups()
    <span class="kw">except</span>:
        <span class="kw">pass</span>
    <span class="kw">else</span>:
        <span class="kw">if</span> elems[<span class="dv">1</span>] == <span class="st">&quot;cpu_usage&quot;</span>:
            cpu_usages.append(<span class="dt">int</span>(elems[<span class="dv">2</span>]))

<span class="kw">if</span> <span class="dt">__name__</span> == <span class="st">&quot;__main__&quot;</span>:
    main()</code></pre></td></tr></table>
<p>Looking at this script there are many possible reasons for performance problems:</p>
<ul>
<li>Looping over a compressed file must be slow! Surely we can afford larger hard drives, keep logs decompressed, and the script will become much faster?</li>
<li>The regular expression looks quite inefficient! It needs tuning.</li>
<li>Process calls in Python have a very large overhead. We should be avoiding function calls within inner loops.</li>
<li>What is going on with the regular expression matching?! Exception handling?!</li>
<li>Maybe computing the average would be faster if we maintained a running sum rather than storing all the values in a giant array. We’d save memory too!</li>
</ul>
<p>These are all valid points. However, put aside the toy script for a moment and consider the bigger picture. You may instead be faced with a convulted, complex, and poorly documented system, where such points are not obvious. Hence, instead of jumping in and “optimising” the code, your response to anyone who suggests such “optimisations”, in simple or complex scenarios, is always:</p>
<blockquote>
<p>&quot;Before we waste time on <strong>opinions</strong> I’d like to proceed on the basis of <strong>empirical measurements</strong>.</p>
</blockquote>
<h4 id="cprofile"><a href="#cprofile">cProfile</a></h4>
<p><code>cProfile</code><span class="citation"><sup><a href="#fn22" class="footnoteRef" id="fnref22">22</a></sup></span> is a deterministic profiler that’s part of the Python standard library. It’s easy to use, efficient enough that it has neglible impact on many programmes, and with a little trickery can be used with a decorator to profile individual functions.</p>
<p>To use it on our toy example:</p>
<pre><code>python -m cProfile -o profile.stats parse_log.py</code></pre>
<p>This will output a file <code>profile.stats</code> to the current working directory. It contains low-level details that may be parsed out and summarised. One command I like using sorts the statistics by total time spent in particular functions, as follows:</p>
<pre><code>(going_faster_with_python)Mill:src ai$ python -c &quot;import pstats; p = pstats.Stats(&#39;profile.stats&#39;);
p.sort_stats(&#39;time&#39;).print_stats(5)&quot;
Sun Mar  3 17:49:04 2013    profile.stats

         20000398 function calls (20000376 primitive calls) in 31.770 seconds

   Ordered by: internal time
   List reduced from 67 to 5 due to restriction &lt;5&gt;

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
  5000000   12.930    0.000   23.044    0.000 cpu_profiling/parse_log.py:31(process_line)
        1    8.666    8.666   31.756   31.756 cpu_profiling/parse_log.py:21(main)
  5000000    7.917    0.000    7.917    0.000 {method &#39;search&#39; of &#39;_sre.SRE_Pattern&#39; objects}
  5000000    1.621    0.000    1.621    0.000 {method &#39;groups&#39; of &#39;_sre.SRE_Match&#39; objects}
  5000065    0.575    0.000    0.575    0.000 {method &#39;append&#39; of &#39;list&#39; objects}</code></pre>
<p>Interpreting the results:</p>
<ul>
<li>The script took approximately 31.8 seconds to execute.</li>
<li>The <strong>tottime</strong> column specifies the total time spent in a function and <em>excludes</em> time spent in calls to sub functions.</li>
<li>The <strong>cumtime</strong> column specifies the total time spent in a function and <em>includes</em> time spent in calls to sub functions.</li>
<li>12.9 seconds, or 40.7% of the total time, was spent in <code>process_line()</code>, and this <em>excludes</em> time spent in calls to the regular expression module. It was called five million times.</li>
<li>8.67 seconds, or 27.2% of the total time, was spent in <code>process_log()</code>, and this <em>excludes</em> time spent in the five millions calls to <code>process_line()</code>.</li>
<li>7.92 seconds, or 25% of the total time, was spent calling <code>re.search()</code>, i.e. using our regular expression.</li>
<li>The top three functions account for <span class="math">\(\frac{12.9 + 8.67 + 7.92}{31.8} \times 100 = 92.7\textrm{%}\)</span> of the total execution time.</li>
</ul>
<p>What can we conclude from the results? These conclusions are <strong>ordered</strong> from most to least important:</p>
<ul>
<li>There is something terribly wrong with <code>process_line()</code> that is <strong>independent</strong> of the regular expression used and the list append operation.
<ul>
<li>Looking at the function this suggests that the non-idiomatic usage of exception handling is causing us pain. (Why? Stay tuned for the “CPython and Bytecode Analysis” section to learn more).</li>
<li>Instead of doing a string comparison on the results of the regular expression why couldn’t we get the regular expression to do this comparison for us, by putting <code>cpu_usage</code> into the regular expression itself?</li>
</ul></li>
<li>There is something about the <code>main()</code> function, <strong>independent</strong> of calls to sub functions, that is slow. Looking at the function this must largely be the decompression of the bzip2-compressed log file. Your options depend on your requirements. Could you get away with gzip compression instead, which consumes less CPU resources at the cost of a lower compression ratio? Could you get away with no compression?</li>
<li>What’s wrong with our regular expression? It seems a bit slow! Could we re-write it to make it faster? (Hint: yes).</li>
<li><code>summarise()</code> isn’t even in the top five. Although this is not the most efficient manner in which to calculate an arithmetic mean it is most certainly <strong>completely irrelevant at this stage of our investigation</strong>.</li>
</ul>
<p>You can also use the cProfiler output to trace which functions are calling whom. Rather than cover that in detail here I’m going to cover the same functionality in a better user interface in the “callgrind” section below. However, here is how you’d get such information from the command-line for who is <em>calling</em> the hot functions:</p>
<pre><code>(going_faster_with_python)Mill:src ai$ python -c &quot;import pstats;
p = pstats.Stats(&#39;profile.stats&#39;);
p.sort_stats(&#39;cumulative&#39;).print_callers(5)&quot;

   Ordered by: cumulative time
   List reduced from 67 to 5 due to restriction &lt;5&gt;

Function                                         was called by...
                                                     ncalls  tottime  cumtime
cpu_profiling/parse_log.py:3(&lt;module&gt;)           &lt;-
cpu_profiling/parse_log.py:21(main)              &lt;-       1    7.869   27.992  cpu_profiling/parse_log.py:3(&lt;module&gt;)
cpu_profiling/parse_log.py:31(process_line)      &lt;- 5000000   11.267   20.078  cpu_profiling/parse_log.py:21(main)
{method &#39;search&#39; of &#39;_sre.SRE_Pattern&#39; objects}  &lt;- 5000000    6.946    6.946  cpu_profiling/parse_log.py:31(process_line)
{method &#39;groups&#39; of &#39;_sre.SRE_Match&#39; objects}    &lt;- 5000000    1.360    1.360  cpu_profiling/parse_log.py:31(process_line)</code></pre>
<p>and for who <em>the hot functions are calling</em>:</p>
<pre><code>(going_faster_with_python)Mill:src ai$ python -c &quot;import pstats;
p = pstats.Stats(&#39;profile.stats&#39;);
p.sort_stats(&#39;cumulative&#39;).print_callees(5)&quot;

   Ordered by: cumulative time
   List reduced from 67 to 5 due to restriction &lt;5&gt;

Function                                         called...
                                                     ncalls  tottime  cumtime
cpu_profiling/parse_log.py:3(&lt;module&gt;)           -&gt;       3    0.000    0.000  /Users/ai/Programming/.envs/going_faster_with_python/lib/python2.7/posixpath.py:60(join)
                                                          1    0.000    0.000  /Users/ai/Programming/.envs/going_faster_with_python/lib/python2.7/posixpath.py:341(abspath)
                                                          1    0.000    0.000  /Users/ai/Programming/.envs/going_faster_with_python/lib/python2.7/re.py:188(compile)
                                                          1    0.000    0.000  /usr/local/Cellar/python/2.7.3/lib/python2.7/__future__.py:48(&lt;module&gt;)
                                                          1    0.000    0.000  /usr/local/Cellar/python/2.7.3/lib/python2.7/contextlib.py:1(&lt;module&gt;)
                                                          1    7.869   27.992  cpu_profiling/parse_log.py:21(main)
cpu_profiling/parse_log.py:21(main)              -&gt;       1    0.000    0.000  /usr/local/Cellar/python/2.7.3/lib/python2.7/contextlib.py:149(__init__)
                                                          1    0.000    0.000  /usr/local/Cellar/python/2.7.3/lib/python2.7/contextlib.py:151(__enter__)
                                                          1    0.000    0.001  /usr/local/Cellar/python/2.7.3/lib/python2.7/contextlib.py:153(__exit__)
                                                          1    0.000    0.045  cpu_profiling/parse_log.py:28(summarise)
                                                    5000000   11.267   20.078  cpu_profiling/parse_log.py:31(process_line)
cpu_profiling/parse_log.py:31(process_line)      -&gt; 5000000    0.505    0.505  {method &#39;append&#39; of &#39;list&#39; objects}
                                                    5000000    1.360    1.360  {method &#39;groups&#39; of &#39;_sre.SRE_Match&#39; objects}
                                                    5000000    6.946    6.946  {method &#39;search&#39; of &#39;_sre.SRE_Pattern&#39; objects}
{method &#39;search&#39; of &#39;_sre.SRE_Pattern&#39; objects}  -&gt;
{method &#39;groups&#39; of &#39;_sre.SRE_Match&#39; objects}    -&gt;</code></pre>
<p>A final trick with <code>cProfile</code> is that you can craft a decorator to only trigger it for particular functions. This is useful when the overhead of <code>cProfile</code> over <em>all</em> the code is too high, but you need a profile of a function and called subfunctions:<span class="citation"><sup><a href="#fn23" class="footnoteRef" id="fnref23">23</a></sup></span></p>
<table class="sourceCode python numberLines"><tr class="sourceCode"><td class="lineNumbers"><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
</pre></td><td class="sourceCode"><pre><code class="sourceCode python"><span class="ch">import</span> cProfile

<span class="kw">def</span> profileit(name):
    <span class="kw">def</span> inner(func):
        <span class="kw">def</span> wrapper(*args, **kwargs):
            prof = cProfile.Profile()
            retval = prof.runcall(func, *args, **kwargs)
            <span class="co"># Note use of name from outer scope</span>
            prof.dump_stats(name)
            <span class="kw">return</span> retval
        <span class="kw">return</span> wrapper
    <span class="kw">return</span> inner

<span class="ot">@profileit</span>(<span class="st">&quot;profile_for_func1_001&quot;</span>)
<span class="kw">def</span> func1(...)
    ...</code></pre></td></tr></table>
<h4 id="line_profiler"><a href="#line_profiler">line_profiler</a></h4>
<p><code>cProfiler</code> is rather coarse because it only traces function calls, and so is only precise at the function call level. Using a module called <code>line_profiler</code> we can measure CPU occupancy at the line-level.</p>
<p>After a <code>pip install line_profiler</code> you just need to decorate the functions you’re interested in with <code>@profile</code>. Note that this will render the script unexecutable because we do not use any imported modules to profile our script. I’ve already done the decorating in <code>src/cpu_profiling/parse_log_line_profiler.py</code>. Afterward execute <code>kernprof.py</code>:</p>
<pre><code>(going_faster_with_python)Mill:src ai$ kernprof.py -l -v cpu_profiling/parse_log_line_profiler.py

avg: 49.9978002
Wrote profile results to parse_log_line_profiler.py.lprof
Timer unit: 1e-06 s

File: cpu_profiling/parse_log_line_profiler.py
Function: main at line 21
Total time: 105.217 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    21                                           @profile
    22                                           def main():
    23         1            2      2.0      0.0      cpu_usages = []
    24         1           34     34.0      0.0      with contextlib.closing(bz2.BZ2File(log_filepath)) as f_in:
    25   5000001     11602598      2.3     11.0          for line in f_in:
    26   5000000     93565103     18.7     88.9              process_line(line, cpu_usages)
    27         1        49088  49088.0      0.0      summarise(cpu_usages)

File: cpu_profiling/parse_log_line_profiler.py
Function: process_line at line 32
Total time: 44.2081 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    32                                           @profile
    33                                           def process_line(line, cpu_usages):
    34   5000000     14758591      3.0     33.4      re_obj = re_log_line.search(line)
    35   5000000      4406648      0.9     10.0      try:
    36   5000000      6765236      1.4     15.3          elems = re_obj.groups()
    37                                               except:
    38                                                   pass
    39                                               else:
    40   5000000      5814440      1.2     13.2          if elems[1] == &quot;cpu_usage&quot;:
    41   5000000     12463137      2.5     28.2              cpu_usages.append(int(elems[2]))</code></pre>
<p>The output is quite intuitive and you’ll note it confirms many of our intuitions from the “cProfiler” section. We already knew that <code>process_line()</code> was quite slow. However, <code>line_profiler</code> indicates that appending to a list in order to track CPU usage takes up 30% of the execution time of the function. Is it, however, the <code>append</code> itself, the <code>int</code>, or the array access that takes up this time? You’d need to do a bit of <strong>refactoring</strong> and spread the code over several lines to aid <code>line_profiler</code>.</p>
<p>However, the “total time” values seem a bit off. Why did <code>cProfiler</code> run the script in 30-odd seconds and this one is spending eons just in the individual functions? Recall that both <code>cProfiler</code> and <code>line_profiler</code> are instances of <strong>deterministic profilers</strong>; in fact the actual execution of our script is faster without such profiling (although cProfiler doesn’t add <em>that</em> much overhead):</p>
<pre><code>(going_faster_with_python)Mill:src ai$ python utilities/measureproc.py python cpu_profiling/parse_log.py

Summary of 5 runs
metric  | min   | Q1    | median | Q2    | max  
--------+-------+-------+--------+-------+------
clock   | 24.15 | 24.23 | 24.67  | 26.02 | 31.76
user    | 24.00 | 24.12 | 24.48  | 25.86 | 30.46
system  | 0.07  | 0.09  | 0.09   | 0.11  | 0.15 
rss_max | 46.02 | 46.04 | 46.04  | 46.04 | 46.05</code></pre>
<h4 id="callgrind"><a href="#callgrind">callgrind</a></h4>
<p>TODO</p>
<p>This is far superior to RunSnakeRun, and to boot is actually usable.</p>
<p>Installation on Mac OS X:</p>
<ul>
<li>You’ll need XCode Developer Tools.</li>
<li><code>brew install qt graphview</code></li>
<li>Download the KCachegrind source.<span class="citation"><sup><a href="#fn24" class="footnoteRef" id="fnref24">24</a></sup></span></li>
<li><code>cd kcachegrind/qcachegrind</code></li>
<li><code>qmake; make</code></li>
<li>You’ll have a <code>qcachegrind.app</code>, move it to Applications.</li>
<li>callgrind wants the Graphviz executable <code>dot</code> to be accessible without a <code>~/.bash_profile</code>, so you need to <code>sudo ln -s /usr/local/bin/dot /usr/bin/dot</code></li>
<li><code>pip install pyprof2calltree</code></li>
</ul>
<p>To use this:</p>
<ul>
<li>Generate a regular <code>cProfile</code> profile file (see earlier).</li>
<li><code>pyprof2calltree -i cprofile.out -o callgrind.output</code></li>
<li>Open <code>callgrind.output</code> in QCachegrind.</li>
<li>Pretty pictures!</li>
</ul>
<p>For more information see,<span class="citation"><sup><a href="#fn25" class="footnoteRef" id="fnref25">25</a></sup></span>.<span class="citation"><sup><a href="#fn26" class="footnoteRef" id="fnref26">26</a></sup></span></p>
<h4 id="profilestats"><a href="#profilestats">profilestats</a></h4>
<p>TODO</p>
<p>Decorator for profiling individual functions then converting the profiling data to kcachegrind format. Of course you could just use the <code>cProfile</code> decorator trick explained above and then call <code>pyprof2calltree</code>, but to each their own.</p>
<p>To install this: <code>pip install profilestats</code>.</p>
<p>Usage:</p>
<ul>
<li><code>from profilestats import profile</code></li>
<li><code>@profile</code> on function.</li>
</ul>
<p>For more information see.<span class="citation"><sup><a href="#fn27" class="footnoteRef" id="fnref27">27</a></sup></span></p>
<h4 id="statprof"><a href="#statprof">statprof</a></h4>
<p>TODO</p>
<p>Statistical profiler. Intended to have lighter impact than <code>cProfiler</code>. It regularly gathers the stack on a timer, rather than deterministically tracing all calls.</p>
<p>To install: <code>pip install statprof</code>.</p>
<p>To use:</p>
<table class="sourceCode python numberLines"><tr class="sourceCode"><td class="lineNumbers"><pre>1
2
3
4
5
6
7
8
</pre></td><td class="sourceCode"><pre><code class="sourceCode python"><span class="ch">import</span> statprof

statprof.start()
    <span class="kw">try</span>:
        my_questionable_function()
    <span class="kw">finally</span>:
        statprof.stop()
        statprof.display()</code></pre></td></tr></table>
<p>For more information see.<span class="citation"><sup><a href="#fn28" class="footnoteRef" id="fnref28">28</a></sup></span></p>
<h4 id="plop"><a href="#plop">plop</a></h4>
<p>TODO</p>
<p>Statistical profiler, low CPU overhead.</p>
<p>To install: <code>pip install plop tornado</code></p>
<p>To use:</p>
<ul>
<li><code>python -m plop.collectory myscript.py</code></li>
<li>Writes output to <code>/tmp/plop.out</code></li>
<li><code>python -m python.viewer --datadir=/tmp</code></li>
<li>This launches a Tornado web server.</li>
<li>Browse to <a href="http://localhost:8888">http://localhost:8888</a></li>
<li>Pretty pictures!
<ul>
<li>D3 force-layout directed call graph.</li>
<li>Radius of node is percentage of total time it takes.</li>
</ul></li>
</ul>
<p>For more information see,<span class="citation"><sup><a href="#fn29" class="footnoteRef" id="fnref29">29</a></sup></span><span class="citation"><sup><a href="#fn30" class="footnoteRef" id="fnref30">30</a></sup></span></p>
<h3 id="memory-profiling"><a href="#memory-profiling">Memory profiling</a></h3>
<p>TODO</p>
<h4 id="pympler"><a href="#pympler">pympler</a></h4>
<p>TODO</p>
<h4 id="maliae"><a href="#maliae">maliae</a></h4>
<p>TODO</p>
<h2 id="part-3---how-do-i-optimise"><a href="#part-3---how-do-i-optimise">Part 3 - How Do I Optimise?</a></h2>
<h3 id="introduction-1"><a href="#introduction-1">Introduction</a></h3>
<h3 id="cpython-and-bytecode-analysis"><a href="#cpython-and-bytecode-analysis">CPython and Bytecode Analysis</a></h3>
<pre class="sourceCode python"><code class="sourceCode python"><span class="ch">import</span> this
<span class="kw">for</span> i in <span class="dt">xrange</span>(<span class="dv">5</span>):
    <span class="kw">print</span> i</code></pre>
<h3 id="cython"><a href="#cython">Cython</a></h3>
<h3 id="numpy"><a href="#numpy">numpy</a></h3>
<h3 id="cython-with-numpy"><a href="#cython-with-numpy">Cython with numpy</a></h3>
<h3 id="pypy"><a href="#pypy">PyPy</a></h3>
<h2 id="part-4---case-study-1---a-log-parser"><a href="#part-4---case-study-1---a-log-parser">Part 4 - Case Study 1 - A Log Parser</a></h2>
<h3 id="introduction-2"><a href="#introduction-2">Introduction</a></h3>
<h3 id="use-cases"><a href="#use-cases">Use Cases</a></h3>
<h3 id="initial-code"><a href="#initial-code">Initial Code</a></h3>
<h3 id="initial-profiling"><a href="#initial-profiling">Initial Profiling</a></h3>
<h2 id="part-5---case-study-2---n-gram-language-models"><a href="#part-5---case-study-2---n-gram-language-models">Part 5 - Case Study 2 - N-gram Language Models</a></h2>
<h3 id="introduction-3"><a href="#introduction-3">Introduction</a></h3>
<h3 id="use-cases-1"><a href="#use-cases-1">Use Cases</a></h3>
<h3 id="initial-code-1"><a href="#initial-code-1">Initial Code</a></h3>
<h3 id="initial-profiling-1"><a href="#initial-profiling-1">Initial Profiling</a></h3>
<h2 id="references"><a href="#references">References</a></h2>
<p>Cramer, David. “Django-debug-toolbar.” Accessed February 26, 2013. <a href="https://github.com/django-debug-toolbar/django-debug-toolbar" title="https://github.com/django-debug-toolbar/django-debug-toolbar">https://github.com/django-debug-toolbar/django-debug-toolbar</a>.</p>
<p>Darnell, Ben. “Plop: Low-overhead Profiling for Python.” Accessed March 06, 2013. <a href="https://tech.dropbox.com/2012/07/plop-low-overhead-profiling-for-python/" title="https://tech.dropbox.com/2012/07/plop-low-overhead-profiling-for-python/">https://tech.dropbox.com/2012/07/plop-low-overhead-profiling-for-python/</a>.</p>
<p>———. “Plop.” Accessed March 06, 2013. <a href="https://github.com/bdarnell/plop" title="https://github.com/bdarnell/plop">https://github.com/bdarnell/plop</a>.</p>
<p>Fowler, Martin, and Kent Beck. <em>Refactoring: Improving the Design of Existing Code</em>. Addison-Wesley Professional, 1999.</p>
<p>Hellman, Doug. “CProfile.” Accessed February 26, 2013. <a href="http://pymotw.com/2/profile/index.html" title="http://pymotw.com/2/profile/index.html">http://pymotw.com/2/profile/index.html</a>.</p>
<p>Ihsan, Asim. “Generate_log.py.” Accessed March 03, 2013. <a href="https://github.com/asimihsan/going_faster_with_python/blob/master/src/utilities/generate_log.py" title="https://github.com/asimihsan/going_faster_with_python/blob/master/src/utilities/generate_log.py">https://github.com/asimihsan/going_faster_with_python/blob/master/src/utilities/generate_log.py</a>.</p>
<p>———. “Measureproc.py.” Accessed March 03, 2013. <a href="https://github.com/asimihsan/going_faster_with_python/blob/master/src/utilities/measureproc.py" title="https://github.com/asimihsan/going_faster_with_python/blob/master/src/utilities/measureproc.py">https://github.com/asimihsan/going_faster_with_python/blob/master/src/utilities/measureproc.py</a>.</p>
<p>———. “Parse_log.py.” Accessed March 03, 2013. <a href="https://github.com/asimihsan/going_faster_with_python/blob/master/src/cpu_profiling/parse_log.py" title="https://github.com/asimihsan/going_faster_with_python/blob/master/src/cpu_profiling/parse_log.py">https://github.com/asimihsan/going_faster_with_python/blob/master/src/cpu_profiling/parse_log.py</a>.</p>
<p>Knuth, Donald E. “An Empirical Study of FORTRAN Programs.” <em>Software: Practice and Experience</em> 1, no. 2: 105–133.</p>
<p>———. “Structured Programming With Go To Statements.” <em>Computing Surveys</em> 6: 261–301.</p>
<p>Leskes, Boaz. “PyCounter.” Accessed March 06, 2013. <a href="http://pycounters.readthedocs.org/en/latest/" title="http://pycounters.readthedocs.org/en/latest/">http://pycounters.readthedocs.org/en/latest/</a>.</p>
<p>McConnell, Steve. <em>Code Complete</em>. Microsoft Press, 2009.</p>
<p>Oram, Andy, and Greg Wilson. <em>Beautiful Code: Leading Programmers Explain How They Think</em>. O’Reilly Media, Incorporated, 2007.</p>
<p>O’Sullivan, Bryan. “Statprof.” Accessed March 06, 2013. <a href="https://github.com/bos/statprof.py" title="https://github.com/bos/statprof.py">https://github.com/bos/statprof.py</a>.</p>
<p>Patterson, David A., and John L. Hennessy. <em>Computer Organization and Design: The Hardware/Software Interface</em>. Morgan Kaufmann, 2009.</p>
<p>PythonDocs. “Logger.exception.” Accessed February 26, 2013. <a href="http://docs.python.org/2/library/logging.html logging.Logger.exception" title="http://docs.python.org/2/library/logging.html logging.Logger.exception">http://docs.python.org/2/library/logging.html logging.Logger.exception</a>.</p>
<p>———. “Multiprocessing.” Accessed February 24, 2013. <a href="http://docs.python.org/2/library/multiprocessing.html" title="http://docs.python.org/2/library/multiprocessing.html">http://docs.python.org/2/library/multiprocessing.html</a>.</p>
<p>Schlichting, Hanno. “Profilestats.” Accessed March 06, 2013. <a href="https://pypi.python.org/pypi/profilestats" title="https://pypi.python.org/pypi/profilestats">https://pypi.python.org/pypi/profilestats</a>.</p>
<p>Sedgewick, Robert, and Kevin Wayne. <em>Algorithms</em>. 4 ed. Addison-Wesley Professional, 2011.</p>
<p>Sentry. “Sentry.” Accessed February 26, 2013. <a href="https://www.getsentry.com/" title="https://www.getsentry.com/">https://www.getsentry.com/</a>.</p>
<p>Sissel, Jordan. “Logstash.” Accessed February 26, 2013. <a href="http://www.logstash.net/" title="http://www.logstash.net/">http://www.logstash.net/</a>.</p>
<p>Solem, Ask. “Celery.” Accessed February 24, 2013. <a href="http://www.celeryproject.org/" title="http://www.celeryproject.org/">http://www.celeryproject.org/</a>.</p>
<p>Tsui, Frank, and Orlando Karam. <em>Essentials of Software Engineering</em>. Jones &amp; Bartlett Learning, 2010.</p>
<p>Vanovschi, Vitalii. “ParallelPython.” Accessed February 24, 2013. <a href="http://www.parallelpython.com/" title="http://www.parallelpython.com/">http://www.parallelpython.com/</a>.</p>
<p>Weidendorfer, Josef. “KCachegrind.” Accessed March 06, 2013. <a href="http://kcachegrind.sourceforge.net/html/Home.html" title="http://kcachegrind.sourceforge.net/html/Home.html">http://kcachegrind.sourceforge.net/html/Home.html</a>.</p>
<p>———. “KCachegrind Source.” Accessed March 06, 2013. <a href="http://kcachegrind.sourceforge.net/html/Download.html" title="http://kcachegrind.sourceforge.net/html/Download.html">http://kcachegrind.sourceforge.net/html/Download.html</a>.</p>
<p>Williams, Lloyd G., and Connie U. Smith. “Five Steps To Solving Software Performance Problems.” <em>Software Engineering Research and Performance Engineering Services</em>.</p>
<p>jsdalton. “CProfile Decorator (Stackoverflow).” Accessed March 03, 2013. <a href="http://stackoverflow.com/questions/5375624/a-decorator-that-profiles-a-method-call-and-logs-the-profiling-result" title="http://stackoverflow.com/questions/5375624/a-decorator-that-profiles-a-method-call-and-logs-the-profiling-result">http://stackoverflow.com/questions/5375624/a-decorator-that-profiles-a-method-call-and-logs-the-profiling-result</a>.</p>
<p>justfalter. “How To Install Qcachegrind (kcachegrind) on Mac OSX Snow Leopard.” Accessed March 06, 2013. <a href="http://langui.sh/2011/06/16/how-to-install-qcachegrind-kcachegrind-on-mac-osx-snow-leopard/" title="http://langui.sh/2011/06/16/how-to-install-qcachegrind-kcachegrind-on-mac-osx-snow-leopard/">http://langui.sh/2011/06/16/how-to-install-qcachegrind-kcachegrind-on-mac-osx-snow-leopard/</a>.</p>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>PythonDocs, “Multiprocessing,” accessed February 24, 2013, <a href="http://docs.python.org/2/library/multiprocessing.html" title="http://docs.python.org/2/library/multiprocessing.html">http://docs.python.org/2/library/multiprocessing.html</a>.<a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>Ask Solem, “Celery,” accessed February 24, 2013, <a href="http://www.celeryproject.org/" title="http://www.celeryproject.org/">http://www.celeryproject.org/</a>.<a href="#fnref2">↩</a></p></li>
<li id="fn3"><p>Vitalii Vanovschi, “ParallelPython,” accessed February 24, 2013, <a href="http://www.parallelpython.com/" title="http://www.parallelpython.com/">http://www.parallelpython.com/</a>.<a href="#fnref3">↩</a></p></li>
<li id="fn4"><p>Donald E. Knuth, “Structured Programming With Go To Statements,” <em>Computing Surveys</em> 6 (1974): 261–301.<a href="#fnref4">↩</a></p></li>
<li id="fn5"><p>Lloyd G. Williams and Connie U. Smith, “Five Steps To Solving Software Performance Problems,” <em>Software Engineering Research and Performance Engineering Services</em> (2002): 2.<a href="#fnref5">↩</a></p></li>
<li id="fn6"><p>Frank Tsui and Orlando Karam, <em>Essentials of Software Engineering</em> (Jones &amp; Bartlett Learning, 2010), chap. 9 ‘Implementation.’<a href="#fnref6">↩</a></p></li>
<li id="fn7"><p>Martin Fowler and Kent Beck, <em>Refactoring: Improving the Design of Existing Code</em> (Addison-Wesley Professional, 1999), chap. 2 ‘Principles in Refactoring.’<a href="#fnref7">↩</a></p></li>
<li id="fn8"><p>Steve McConnell, <em>Code Complete</em> (Microsoft Press, 2009), chap. 25 ‘Code-Tuning Strategies.’<a href="#fnref8">↩</a></p></li>
<li id="fn9"><p>Robert Sedgewick and Kevin Wayne, <em>Algorithms</em>, 4 ed. (Addison-Wesley Professional, 2011).<a href="#fnref9">↩</a></p></li>
<li id="fn10"><p>Donald E. Knuth, “An Empirical Study of FORTRAN Programs,” <em>Software: Practice and Experience</em> 1, no. 2 (1971): 105–133.<a href="#fnref10">↩</a></p></li>
<li id="fn11"><p>David A. Patterson and John L. Hennessy, <em>Computer Organization and Design: The Hardware/Software Interface</em> (Morgan Kaufmann, 2009), chap. 1 ‘Fundamentals of Computer Design.’<a href="#fnref11">↩</a></p></li>
<li id="fn12"><p>Ibid., chap. 1 ‘Fundamentals of Computer Design.’<a href="#fnref12">↩</a></p></li>
<li id="fn13"><p>Andy Oram and Greg Wilson, <em>Beautiful Code: Leading Programmers Explain How They Think</em> (O’Reilly Media, Incorporated, 2007), chap. 5 ‘Correct, Beautiful, Fast.’<a href="#fnref13">↩</a></p></li>
<li id="fn14"><p>Asim Ihsan, “Measureproc.py,” accessed March 03, 2013, <a href="https://github.com/asimihsan/going_faster_with_python/blob/master/src/utilities/measureproc.py" title="https://github.com/asimihsan/going_faster_with_python/blob/master/src/utilities/measureproc.py">https://github.com/asimihsan/going_faster_with_python/blob/master/src/utilities/measureproc.py</a>.<a href="#fnref14">↩</a></p></li>
<li id="fn15"><p>PythonDocs, “Logger.exception,” accessed February 26, 2013, <a href="http://docs.python.org/2/library/logging.html logging.Logger.exception" title="http://docs.python.org/2/library/logging.html logging.Logger.exception">http://docs.python.org/2/library/logging.html logging.Logger.exception</a>.<a href="#fnref15">↩</a></p></li>
<li id="fn16"><p>Sentry, “Sentry,” accessed February 26, 2013, <a href="https://www.getsentry.com/" title="https://www.getsentry.com/">https://www.getsentry.com/</a>.<a href="#fnref16">↩</a></p></li>
<li id="fn17"><p>Jordan Sissel, “Logstash,” accessed February 26, 2013, <a href="http://www.logstash.net/" title="http://www.logstash.net/">http://www.logstash.net/</a>.<a href="#fnref17">↩</a></p></li>
<li id="fn18"><p>David Cramer, “Django-debug-toolbar,” accessed February 26, 2013, <a href="https://github.com/django-debug-toolbar/django-debug-toolbar" title="https://github.com/django-debug-toolbar/django-debug-toolbar">https://github.com/django-debug-toolbar/django-debug-toolbar</a>.<a href="#fnref18">↩</a></p></li>
<li id="fn19"><p>Boaz Leskes, “PyCounter,” accessed March 06, 2013, <a href="http://pycounters.readthedocs.org/en/latest/" title="http://pycounters.readthedocs.org/en/latest/">http://pycounters.readthedocs.org/en/latest/</a>.<a href="#fnref19">↩</a></p></li>
<li id="fn20"><p>Asim Ihsan, “Generate_log.py,” accessed March 03, 2013, <a href="https://github.com/asimihsan/going_faster_with_python/blob/master/src/utilities/generate_log.py" title="https://github.com/asimihsan/going_faster_with_python/blob/master/src/utilities/generate_log.py">https://github.com/asimihsan/going_faster_with_python/blob/master/src/utilities/generate_log.py</a>.<a href="#fnref20">↩</a></p></li>
<li id="fn21"><p>Asim Ihsan, “Parse_log.py,” accessed March 03, 2013, <a href="https://github.com/asimihsan/going_faster_with_python/blob/master/src/cpu_profiling/parse_log.py" title="https://github.com/asimihsan/going_faster_with_python/blob/master/src/cpu_profiling/parse_log.py">https://github.com/asimihsan/going_faster_with_python/blob/master/src/cpu_profiling/parse_log.py</a>.<a href="#fnref21">↩</a></p></li>
<li id="fn22"><p>Doug Hellman, “CProfile,” accessed February 26, 2013, <a href="http://pymotw.com/2/profile/index.html" title="http://pymotw.com/2/profile/index.html">http://pymotw.com/2/profile/index.html</a>.<a href="#fnref22">↩</a></p></li>
<li id="fn23"><p>Jsdalton, “CProfile Decorator (Stackoverflow),” accessed March 03, 2013, <a href="http://stackoverflow.com/questions/5375624/a-decorator-that-profiles-a-method-call-and-logs-the-profiling-result" title="http://stackoverflow.com/questions/5375624/a-decorator-that-profiles-a-method-call-and-logs-the-profiling-result">http://stackoverflow.com/questions/5375624/a-decorator-that-profiles-a-method-call-and-logs-the-profiling-result</a>.<a href="#fnref23">↩</a></p></li>
<li id="fn24"><p>Josef Weidendorfer, “KCachegrind Source,” accessed March 06, 2013, <a href="http://kcachegrind.sourceforge.net/html/Download.html" title="http://kcachegrind.sourceforge.net/html/Download.html">http://kcachegrind.sourceforge.net/html/Download.html</a>.<a href="#fnref24">↩</a></p></li>
<li id="fn25"><p>Josef Weidendorfer, “KCachegrind,” accessed March 06, 2013, <a href="http://kcachegrind.sourceforge.net/html/Home.html" title="http://kcachegrind.sourceforge.net/html/Home.html">http://kcachegrind.sourceforge.net/html/Home.html</a>.<a href="#fnref25">↩</a></p></li>
<li id="fn26"><p>Justfalter, “How To Install Qcachegrind (kcachegrind) on Mac OSX Snow Leopard,” accessed March 06, 2013, <a href="http://langui.sh/2011/06/16/how-to-install-qcachegrind-kcachegrind-on-mac-osx-snow-leopard/" title="http://langui.sh/2011/06/16/how-to-install-qcachegrind-kcachegrind-on-mac-osx-snow-leopard/">http://langui.sh/2011/06/16/how-to-install-qcachegrind-kcachegrind-on-mac-osx-snow-leopard/</a>.<a href="#fnref26">↩</a></p></li>
<li id="fn27"><p>Hanno Schlichting, “Profilestats,” accessed March 06, 2013, <a href="https://pypi.python.org/pypi/profilestats" title="https://pypi.python.org/pypi/profilestats">https://pypi.python.org/pypi/profilestats</a>.<a href="#fnref27">↩</a></p></li>
<li id="fn28"><p>Bryan O’Sullivan, “Statprof,” accessed March 06, 2013, <a href="https://github.com/bos/statprof.py" title="https://github.com/bos/statprof.py">https://github.com/bos/statprof.py</a>.<a href="#fnref28">↩</a></p></li>
<li id="fn29"><p>Ben Darnell, “Plop,” accessed March 06, 2013, <a href="https://github.com/bdarnell/plop" title="https://github.com/bdarnell/plop">https://github.com/bdarnell/plop</a>.<a href="#fnref29">↩</a></p></li>
<li id="fn30"><p>Ben Darnell, “Plop: Low-overhead Profiling for Python,” accessed March 06, 2013, <a href="https://tech.dropbox.com/2012/07/plop-low-overhead-profiling-for-python/" title="https://tech.dropbox.com/2012/07/plop-low-overhead-profiling-for-python/">https://tech.dropbox.com/2012/07/plop-low-overhead-profiling-for-python/</a>.<a href="#fnref30">↩</a></p></li>
</ol>
</div>


<!-- START: Livefyre Embed -->
<div id="livefyre-comments"></div>
<script type="text/javascript" src="http://zor.livefyre.com/wjs/v3.0/javascripts/livefyre.js"></script>
<script type="text/javascript">
(function () {
    var articleId = fyre.conv.load.makeArticleId(null);
    fyre.conv.load({}, [{
        el: 'livefyre-comments',
        network: "livefyre.com",
        siteId: "324868",
        articleId: articleId,
        signed: false,
        collectionMeta: {
            articleId: articleId,
            url: fyre.conv.load.makeCollectionUrl(),
        }
    }], function() {});
}());
</script>
<!-- END: Livefyre Embed -->            

<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-22326574-1']);
  _gaq.push(['_setDomainName', 'asimihsan.com']);
  _gaq.push(['_setAllowLinker', true]);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://' : 'http://') + 'stats.g.doubleclick.net/dc.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>

</body>
</html>
